---
name: proofread-facts
description: 研究論文、統計データ、技術的主張のファクトチェックを行うスキル（厳密モード）
---

# ファクトチェックスキル

## 役割

書籍内の事実に基づく主張を検証し、出典の正確性と情報の鮮度を確認します。

**モード**：厳密（すべての数値・統計に出典を要求）

## 検証対象

### 1. 研究論文・学術的引用

#### 検証項目

| 項目 | 検証内容 |
| --- | --- |
| 論文タイトル | 正式名称と一致しているか |
| 著者名 | 正しく記載されているか |
| 発表年 | 正確か |
| 発表機関 | 正しいか（例：スタンフォード大学） |
| 主張内容 | 論文の結論と一致しているか |

#### 本プロジェクトで引用されている主要論文

```yaml
references:
  - title: "Lost in the Middle: How Language Models Use Long Contexts"
    authors: ["Nelson F. Liu", "Kevin Lin", "John Hewitt", "Ashwin Paranjape", "Michele Bevilacqua", "Fabio Petroni", "Percy Liang"]
    year: 2023
    institution: "Stanford University"
    url: "https://arxiv.org/abs/2307.03172"
    key_findings:
      - "LLMは長い入力の中間部分の情報を見落としやすい"
      - "入力の最初と最後は相対的によく保持される"
```

#### 検証方法

1. 論文名でWebSearchを実行
2. arXiv、Google Scholar、論文公式ページを確認
3. 著者名、年、機関を照合
4. 引用されている主張が論文の結論と一致するか確認

### 2. 統計・数値データ

#### 検証が必要な数値パターン

| パターン | 例 | 必要な出典 |
| --- | --- | --- |
| パーセンテージ | 「70%の完成度」 | 研究データまたは実測値 |
| 具体的な数値 | 「200〜400行」 | 業界標準または研究 |
| 倍率 | 「生産性が3倍」 | 比較研究または実測 |
| 時間 | 「30分で完了」 | 実測データ |
| 人数・回数 | 「23個のコメント」 | 実例または架空であることを明示 |

#### 検証レベル

**🔴 出典必須（統計的主張）**

```
例：「人間がレビューできる限界は、1回あたり200〜400行程度と言われています。」
必要：この数値の出典（研究論文、業界調査など）
```

**🟡 出典推奨（一般的な主張）**

```
例：「多くのエンジニアがこの問題に直面しています。」
推奨：調査データがあればより説得力が増す
```

**✅ 出典不要（例示・仮定）**

```
例：「例えば、100行のコードを書いたとしましょう。」
→ 仮定の例示なので出典不要
```

### 3. 技術的主張

#### LLM/AI関連の主張

| 主張 | 検証方法 |
| --- | --- |
| 「LLMは中間部分を忘れやすい」 | Lost in the Middle論文を確認 |
| 「コンテキストが長いと精度が下がる」 | 関連研究を確認 |
| 「AIは推測に頼る」 | 技術的に正確な表現か確認 |

#### 製品・サービスの仕様

| 項目 | 検証方法 |
| --- | --- |
| Claude/ChatGPTの機能 | 公式ドキュメントを確認 |
| トークン数制限 | 最新の仕様を確認 |
| 価格情報 | 変更されている可能性を警告 |

### 4. URL・外部リンク

#### 検証項目

- URLが有効か（404エラーでないか）
- HTTPSを使用しているか
- リンク先の内容が説明と一致するか

### 5. 情報の鮮度

#### 古い情報の検出

| 期間 | 対応 |
| --- | --- |
| 2年以内 | ✅ 問題なし |
| 2〜3年 | 🟡 確認推奨 |
| 3年以上 | 🔴 更新を検討 |

特に以下は変化が速い：
- AI/LLMの性能・制限
- 価格情報
- APIの仕様
- ライブラリのバージョン

## 検証プロセス

### ステップ1：主張の抽出

テキストから以下を抽出：

1. 数値を含む主張
2. 「〜と言われている」「研究によると」などの表現
3. 論文・著者の言及
4. 外部URLへの参照

### ステップ2：WebSearchによる裏付け

```
検索クエリ例：
- "Lost in the Middle" paper Stanford 2023
- "code review line limit" research study
- "LLM context window performance degradation"
```

### ステップ3：照合と判定

| 結果 | 判定 |
| --- | --- |
| 出典が確認でき、内容が一致 | ✅ 検証済み |
| 出典は確認できるが、詳細が異なる | 🟡 修正推奨 |
| 出典が見つからない | 🔴 出典追加必須 |
| 主張が誤っている | 🔴 修正必須 |

## 出力形式

```markdown
### ファクトチェック結果

#### サマリー
- 検証した主張: X件
- ✅ 検証済み: X件
- 🔴 要修正: X件
- 🟡 確認推奨: X件

---

#### 🔴 要修正（出典なし/誤り）

1. **行227**: 論文引用の正確性
   - 現在: 「2023年、スタンフォード大学の研究者たちが発見した」
   - 事実:
     - 論文名: "Lost in the Middle: How Language Models Use Long Contexts"
     - 著者: Nelson F. Liu et al.
     - 機関: Stanford University（正確）
     - 年: 2023（正確）
   - 推奨: 論文の正式名称と著者名を追記
   - 参照: https://arxiv.org/abs/2307.03172

2. **行103**: 統計データの出典なし
   - 主張: 「人間がレビューできる限界は、1回あたり200〜400行程度」
   - 問題: 出典が明示されていない
   - 調査結果:
     - Cisco研究: "Code Reviews: Just Do It" (200-400 LOC推奨)
     - SmartBear調査: 類似の推奨値
   - 推奨: 出典を追加「〜と言われています[^1]」
   - 脚注案: [^1]: Cisco Systems, "Code Reviews: Just Do It"

---

#### 🟡 確認推奨

1. **行350**: 情報の鮮度
   - 主張: 「GPT-4のコンテキストウィンドウは...」
   - 問題: AI関連の仕様は頻繁に更新される
   - 推奨: 執筆時点の日付を明記、または最新情報を確認

2. **行89**: 外部URL
   - URL: https://example.com/article
   - 状態: アクセス可能
   - 注意: 外部リンクは将来的に無効になる可能性

---

#### ✅ 検証済み

1. **行45**: 「AIに大きなタスクを丸投げすると70%程度で止まる」
   - 種類: 本書独自の概念（経験則）
   - 判定: 仮説として明示されており問題なし

2. **行230**: 「Lost in the Middle」問題
   - 論文: 確認済み（arXiv:2307.03172）
   - 内容: 論文の結論と一致
```

## 脚注の推奨形式

出典を追加する場合の形式：

```markdown
本文中：
「人間がレビューできる限界は、1回あたり200〜400行程度と言われています[^1]。」

章末または文書末：
[^1]: Cisco Systems, "Code Reviews: Just Do It", 2006. https://example.com/link
[^2]: Liu, Nelson F., et al. "Lost in the Middle: How Language Models Use Long Contexts." arXiv:2307.03172, 2023.
```

## 本書で確認すべき主要な主張

### 確認済みリスト

これらは事前に確認された主張です：

1. **Lost in the Middle問題**
   - 論文: arXiv:2307.03172
   - 著者: Nelson F. Liu et al.
   - 年: 2023
   - ✅ 確認済み

### 要確認リスト

新しい章が追加された際に確認が必要：

- [ ] 新しい統計データ
- [ ] 新しい研究論文の引用
- [ ] 製品・サービスの仕様
- [ ] 外部URL

## チェックリスト

検証時に確認すべき項目：

- [ ] 数値を含む主張に出典があるか
- [ ] 論文引用の著者名・年・タイトルは正確か
- [ ] 外部URLは有効か
- [ ] 2年以上前の情報はないか
- [ ] AI/LLM関連の仕様は最新か
- [ ] 価格情報は変更されていないか
