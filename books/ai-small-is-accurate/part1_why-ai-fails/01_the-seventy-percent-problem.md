# 第1章　70%問題──「全部やって」が生む微妙さ

## この章で学ぶこと

- AIに大きなタスクを丸投げすると、なぜ70%程度の完成度で止まってしまうのか
- ChatGPT、Claude、画像生成AIなど、すべてのAIツールに共通する現象
- 「全部やって」と頼むことが、逆に精度を下げる理由

---

## 「ChatGPTに5000字書いてもらったら、なんか微妙だった」話

「AIに任せれば楽になる」

そう思って、ChatGPTにブログ記事を書いてもらったことはありませんか？

```text
プロンプト:
「リモートワークの生産性を高める方法について、
 5000字の包括的な記事を書いてください。」
```

数分後、ChatGPTは見事に5000字の記事を返してくれます。

読んでみると...

### 「悪くはないけど、なんか微妙」

- 一般的な tips の羅列（「集中できる環境を作ろう」「タスク管理ツールを使おう」）
- どこかで見たような内容
- 独自の視点がない
- 深い洞察がない
- 自分のブランドらしさが全くない

「これ、そのままは使えないな...」

結局、大幅に手直しすることに。
期待していた「30分で記事完成」は幻想で、
「AI生成30分＋手直し2時間」というオチになりました。

これ、あなただけの経験ではありません。

---

## どのAIでも起きる「70%で止まる」現象

実は、この「悪くはないけど、なんか微妙」という感覚は、
**どのAIツールでも共通して発生**しています。

| AI用途              | 期待                        | 実際の結果                              | 精度   |
| ------------------- | --------------------------- | --------------------------------------- | ------ |
| ChatGPT文章生成     | 深い洞察のある5000字記事    | 表面的な内容、当たり障りのない文章      | ~70%   |
| Claude コード生成   | 完全な認証システム          | 動くが、セキュリティ標準が微妙          | ~70%   |
| Midjourney ロゴ     | ブランドイメージぴったり    | いい感じだけど、何か違う                | ~70%   |
| 市場調査            | 詳細な分析レポート          | 既知情報の羅列、独自視点なし            | ~70%   |

この「70%」という数字、偶然ではありません。

AIに**大きなタスクを丸投げ**すると、
だいたいこのくらいの完成度で止まってしまうのです。

### 例1：テキスト生成の場合

**依頼内容**:
「プロダクトマネジメントの実践ガイド」というタイトルで、
初心者向けの包括的な記事を5000字で書いてください。

**AIが返してきた内容**:

- プロダクトマネージャーの役割（一般論）
- アジャイル開発の基礎（教科書的）
- ユーザーリサーチの重要性（当たり前）
- ロードマップの作り方（抽象的）

**何が足りないか**:

- 実際のプロダクト開発での失敗談
- 具体的な意思決定のフレームワーク
- チーム間の調整で起きる実際の問題
- 定量データに基づく優先順位付けの方法

**結果**:
「間違ってはいないけど、これを読んでも実務では使えない」

---

### 例2：画像生成の場合

**依頼内容**:
「モダンなテクノロジースタートアップのロゴ。
 プロフェッショナルで記憶に残るデザイン。」

**Midjourneyが返してきたもの**:

- 確かに綺麗
- モダンな雰囲気はある
- テクノロジー感も出ている

**問題点**:

- どこかで見たようなデザイン
- 他の10社と区別がつかない
- ブランドの独自性がゼロ
- 会社のビジョンが伝わらない

**何度修正しても同じ**:
1回目の修正 → 「おしい...でも違う」
2回目の修正 → 「方向性は合ってきたけど...」
3回目の修正 → 「これじゃない感が消えない」

**10回修正した後**:
「もういい、デザイナーに頼もう」

---

### 例3：コード生成の場合

**依頼内容**:
「ユーザー認証システムを実装してください。
 JWT、パスワードハッシュ、リフレッシュトークン、
 ログイン/ログアウト、パスワードリセット機能を含めて。」

**Claudeが生成したコード**:

- ちゃんと動く
- JWTも実装されている
- bcryptでハッシュ化もされている
- エンドポイントも揃っている

**でも、レビューで指摘された問題**:

1. ハッシュアルゴリズムが会社のセキュリティポリシーと異なる（argon2推奨なのにbcrypt）
2. エラーハンドリングが既存パターンと違う
3. 監査ログの実装がない（必須要件なのに）
4. レスポンス形式がAPI標準と不一致
5. テストコードが既存のテストフレームワークと異なる

**結果**:

- PRに23個のコメントがついた
- 修正に2日かかった
- 主要部分を結局書き直した

「AIに頼んで時間を節約しようと思ったのに、
 逆に時間がかかってしまった...」

---

### 例4：調査・分析の場合

**依頼内容**:
「AI業界の最新トレンドを調査して、
 包括的なレポートを作成してください。」

**AIが返してきたレポート**:

- OpenAI、Google、Anthropicの動向（既知）
- 一般的な統計データ（どこでも見る）
- 予測可能な未来予測（ありきたり）

**何が足りないか**:

- ニッチなプレイヤーの動き
- 具体的な数値の裏付け
- 業界インサイダーの視点
- 実務への応用可能性
- 競合の具体的な戦略分析

**使えたのは**:
全体の30%くらい。残りは手動で調査し直し。

**結果**:

- 期待していた時間：30分
- 実際にかかった時間：3時間（手動調査＋AIの出力整理）
- 「最初から自分で調べた方が早かったかも...」

---

## なぜ「全部やって」は失敗するのか

ここまで見てきた例に、共通点があることに気づきましたか？

**すべて「大きなお願い」をしている**ことです。

- 「5000字の包括的な記事を書いて」
- 「完全な認証システムを実装して」
- 「プロダクトのロゴをデザインして」
- 「業界全体を調査して」

そして、すべて**70%くらいの完成度**で止まっています。

なぜでしょうか？

### AIには「見える範囲」に限界がある

人間でも、一度に大量の情報を処理しようとすると、
細部が曖昧になったり、重要なポイントを見落としたりします。

AIも同じです。

いや、AIの方が**この傾向はもっと強い**のです。

想像してみてください。

**小さなタスク**:
> 懐中電灯で照らした1畳の部屋
> → すべての角までくっきり見える

**大きなタスク**:
> 薄暗いライトで照らした10畳の部屋
> → 全体像はぼんやり見えるが、端の方は見えない

AIに大きなタスクを渡すと、こうなります:

```text
【コンテキストサイズと精度の関係】

小さいタスク (100トークン)  → 98%の精度 ✨
中程度 (500トークン)         → 85%の精度 👍
大きいタスク (2000トークン)  → 70%の精度 😐
超大 (5000トークン)          → 50-60%の精度 😞
```

これは単なる比喩ではありません。

2023年、スタンフォード大学の研究者たちが、
LLM（大規模言語モデル）の驚くべき特性を発見しました。

それが**「Lost in the Middle」**問題です。

> **重要な発見**
>
> LLMは長い入力の「中間部分」を忘れやすい。
>
> 最初と最後はよく覚えているが、
> 中間に何があったかは曖昧になる。
>
> そして、入力が長くなるほど、
> この傾向は強くなる。

これが、「全部やって」が失敗する根本原因です。

---

### 大きなお願いが精度を下げるメカニズム

なぜ大きなお願いだと精度が下がるのか？

プロセスを分解してみましょう。

**あなたが AIに依頼**:
「包括的な記事を5000字で書いて」

**AIが処理する情報**:

1. タイトル（リモートワーク生産性）
2. トピック1（環境作り）
3. トピック2（ツール活用）
4. トピック3（時間管理）
5. トピック4（コミュニケーション）
6. トピック5（健康管理）
7. トピック6（メンタルケア）
... さらに多数

**AIの内部で起きていること**:

- すべてのトピックを「同時に」考慮しようとする
- でも、「見える範囲」に限界がある
- 中間のトピックは「ぼやける」
- 各トピックの深掘りができない
- 結果として、表面的な内容になる

**アウトプット**:
一般的で当たり障りのない内容（70%の完成度）

---

### 精度低下の具体的なパターン

#### パターン1：汎用化

**大きなお願い**:
「プロジェクト管理の完全ガイドを書いて」

**AIの思考**:
「プロジェクト管理は幅広いから、
 すべてのケースに当てはまるように書こう」

**結果**:
誰にでも当てはまるが、誰にも役立たない内容

---

#### パターン2：表面化

**大きなお願い**:
「認証システムを完全に実装して」

**AIの思考**:
「認証、認可、セッション、リフレッシュトークン...
 すべてを考慮しなきゃ」

**結果**:
それぞれの実装は動くが、深い考慮（セキュリティ、パフォーマンス、監査）がない

---

#### パターン3：推測の増加

**大きなお願い**:
「会社のロゴをデザインして」

**AIの思考**:
「モダンなテック企業なら、
 きっとこういうデザインが好きだろう」

**結果**:
推測に基づいた汎用的なデザイン（会社固有の要素ゼロ）

---

## 実際に起きる「微妙」の正体

「70%」という完成度が、実際のプロジェクトでどんな影響を与えるか、
3つのケーススタディで見ていきましょう。

### ケース1：市場調査レポート

**背景**:
スタートアップの戦略会議に向けて、
競合分析レポートが必要になった。

**依頼**:
「AI SaaS市場の競合分析レポートを作成して。
 主要プレイヤー、市場規模、トレンド、
 差別化ポイントを含めて。」

**AIが返してきたレポート**:

```markdown
# AI SaaS市場 競合分析レポート

## 市場規模
- 2023年: $XX billion
- 2025年予測: $YY billion
- CAGR: XX%

## 主要プレイヤー
1. OpenAI - ChatGPT Enterprise
2. Google - Vertex AI
3. Anthropic - Claude for Work
... (10社リスト)

## トレンド
- Enterprise adoption が加速
- オンプレミス需要の増加
- 業界特化型AIの登場
```

**一見良さそうに見える。でも...**

戦略会議で使おうとしたら、こんな質問が飛んできた:

- 「OpenAIの直近の価格改定の影響は？」
  → レポートには載っていない

- 「中小規模の競合（SeriesA前後）で注目すべきは？」
  → 大手しか載っていない

- 「導入障壁は何？どう攻略する？」
  → 一般論しか書いていない

- 「実際のユーザーの不満点は？」
  → アンケート結果や口コミ分析がない

**結果**:
レポートの70%を作り直し。
結局、3日かけて独自調査を実施。

**何が悪かったのか**:
「包括的なレポート」という大きなお願いをしたため、

- 表面的な情報の羅列になった
- 戦略立案に必要な「深い洞察」がなかった
- 競合の「弱点」や「攻めどころ」が見えなかった

---

### ケース2：ユーザー管理機能の実装

**背景**:
SaaSプロダクトに新しいユーザー管理機能が必要になった。

**依頼**:
「ユーザー管理システムを実装してください。
 ユーザー登録、ログイン、権限管理、
 プロフィール編集、パスワードリセット機能を含めて。」

**AIが生成したコード**:

```typescript
// 600行のコードが生成された
// - 認証エンドポイント
// - ユーザーCRUD
// - 権限チェックミドルウェア
// - パスワードリセット機能
```

**一見完璧。でも、PRレビューで...**

**レビューコメント（抜粋）**:

1. ❌ セキュリティ: bcrypt使ってるけど、会社標準はargon2
2. ❌ エラーハンドリング: Result型使ってない（プロジェクト標準）
3. ❌ 監査ログ: ログイン試行の記録がない（コンプライアンス必須）
4. ❌ レート制限: ブルートフォース攻撃対策がない
5. ❌ セッション管理: 同時ログインの制御がない
6. ❌ API設計: レスポンス形式がプロジェクト標準と違う
7. ❌ データベース: マイグレーションファイルがない
8. ❌ テスト: E2Eテストがない、単体テストの coverage が不十分
9. ❌ ドキュメント: API docが自動生成されない形式
10. ❌ 型定義: 共通の型定義ファイルを参照していない

... さらに13個のコメント

**修正にかかった時間**:

- 当初の期待：「AIが書いてくれるから1日で終わる」
- レビュー＋修正：2日
- 再レビュー＋再修正：1日
- 主要部分の書き直し：2日
- **合計：5日**

**手動で書いた場合の見積もり**:
3日（最初からプロジェクト標準に沿って書く）

**結論**:
「AIに任せた方が遅かった」

---

### ケース3：プロダクトローンチの資料作成

**背景**:
新プロダクトのローンチに向けて、
マーケティング資料が必要になった。

**依頼**:
「新プロダクトのマーケティングプレゼン資料を作成してください。
 ターゲット顧客、課題、ソリューション、差別化要因、
 価格戦略を含む10-15枚のスライドで。」

**AIが作成した資料**:

```text
スライド1: タイトル
スライド2: 市場の課題（一般論）
スライド3: ソリューション概要
スライド4-7: 機能説明
スライド8: 競合比較（表形式）
スライド9: 価格プラン
スライド10: まとめ
```

**一見良さそう。でも、実際にチームでレビューすると...**

**問題点**:

1. **ビジュアルの一貫性がない**
   - スライドごとにデザインテイストが違う
   - ブランドガイドラインを無視

2. **メッセージが曖昧**
   - ターゲット顧客が「スタートアップ」としか書いていない
   - 具体的なペルソナがない（エンジニア？営業？経営者？）

3. **差別化が弱い**
   - 「高速」「簡単」「安全」という汎用的な言葉だけ
   - 競合と何が違うのか不明確

4. **データがない**
   - 「生産性が向上します」→ どのくらい？
   - 「コストを削減」→ 具体的に何%？

**修正の繰り返し**:

**1回目の修正依頼**:
「ターゲットをもっと具体的に。エンジニアリングマネージャー向けで。」

→ 変わったのはタイトルだけ。内容は汎用的なまま。

**2回目の修正依頼**:
「競合との違いをもっと明確に。APIの柔軟性が強みなんです。」

→ スライド8の競合比較表に「API柔軟性: ◎」が追加されただけ。

**3回目の修正依頼**:
「ブランドカラー（青＋オレンジ）を使って、デザインを統一して。」

→ デザインは変わったが、今度はフォントが読みにくくなった。

**10回目の修正**:
「もういい、デザイナーに頼もう」

---

## 「70%」が引き起こす隠れたコスト

ここまで見てきた例から、
「70%の完成度」が実際に引き起こすコストを整理してみましょう。

### コスト1：時間コスト

**期待していたシナリオ**:

```text
AIに依頼 (5分)
 ↓
完成 (30分でAIが生成)
 ↓
軽く確認して完了 (5分)
────────────────
合計：40分
```

**実際に起きたこと**:

```text
AIに依頼 (5分)
 ↓
AI生成 (30分)
 ↓
「あれ、なんか違う」(15分で気づく)
 ↓
修正依頼 (10分)
 ↓
2回目の生成 (30分)
 ↓
「まだ違う...」(20分で気づく)
 ↓
3回目の修正依頼 (15分)
 ↓
3回目の生成 (30分)
 ↓
「もう自分で直す」(2時間)
────────────────
合計：約4時間
```

**手動で最初から作った場合の見積もり**:
2時間

**結論**:
AIに頼んだ方が**2倍時間がかかった**

---

### コスト2：認知的コスト

「何が間違っているか」を特定する精神的負荷:

1. **AIの出力を評価する負荷**
   - 「これ、本当に正しいのか？」
   - 「どこが間違っているのか？」
   - 「どう直せばいいのか？」

2. **修正指示を考える負荷**
   - 「どう言えば、AIは理解してくれるのか？」
   - 「前回の指示が悪かったのか？」
   - 「もっと具体的に指示すべきか？」

3. **フラストレーションの蓄積**
   - 「なんでこうなるんだ...」
   - 「さっきと言ってること同じなのに」
   - 「もう疲れた」

**結果**:
本来の仕事（戦略立案、コード設計、クリエイティブ思考）に
使うべき認知リソースが消耗される。

---

### コスト3：機会コスト

AI の修正に使った4時間で、
本来できたはずのこと:

- ✅ 新機能のプロトタイプを1つ作れた
- ✅ 顧客インタビューを3件実施できた
- ✅ 技術記事を2本書けた
- ✅ チームメンバーとの1on1を4回できた

**失われた価値**:
目に見える「時間」だけでなく、
その時間で生み出せたはずの「価値」も失われる。

---

### コスト4：チームコスト

一人で完結しない場合、影響は拡大します。

#### 例：コードレビューの場合

**レビュワーの視点**:

```text
AIが書いたコードを見る
 ↓
「あれ？これ、プロジェクト標準と違うな」
 ↓
23個のコメントを書く (1時間)
 ↓
修正を待つ (1日)
 ↓
再レビュー (30分)
 ↓
「まだ直ってない箇所がある...」
 ↓
再度コメント (30分)
 ↓
3回目のレビュー (30分)
```

**レビュワーの消費時間**: 合計3時間

**本来のレビュー時間** (プロジェクト標準に沿ったコード):
30分

**結論**:
一人の「時間節約」のために、
チーム全体で**6倍の時間**を使った。

---

### 感情的な旅路

「70%問題」は、単なる時間やコストの問題ではありません。

ユーザーの**感情的な旅路**にも影響します。

```text
1. 期待の段階 😊
   「AIが助けてくれる！時短できる！」

   ↓

2. 初期の満足 😃
   「お、なかなか良いかも！AIすごい！」

   ↓

3. 疑問の発生 🤔
   「あれ？ここ、ちょっと違うな...」

   ↓

4. 修正の連鎖 😐
   「直したら別のところが...」
   「また違う...」

   ↓

5. フラストレーション 😤
   「もう自分でやる！」

   ↓

6. AI不信 😔
   「AIって結局使えないんじゃないか...」
```

**最終的な結論**:
「AIは期待外れだった」

でも、本当にそうでしょうか？

---

## 解決策のヒント：コンテキスト縮小戦略

ここまで、「70%問題」の深刻さを見てきました。

でも、諦めるのは早いです。

実は、**解決策は存在します**。

その鍵が、**「コンテキスト縮小戦略」**です。

> **コンテキスト縮小戦略**
>
> 大きなお願いを小さく分ける。
> AIが一度に処理する情報量を減らす。
>
> 小さく分ける → AIが全体を見渡せる → 精度が上がる

具体的にどういうことか、3つの例で見てみましょう。

---

### ティーザー例1：文章生成の場合

**Before（70%の精度）**:

```text
依頼: 「リモートワーク生産性について、5000字の記事を書いて」
結果: 表面的で汎用的な内容
```

**After（98%の精度）**:

```text
ステップ1: 「リモートワーク生産性で、重要なポイントを5つ挙げて」
        → 見出しが返ってくる

ステップ2: 「1つ目の見出し『集中環境の作り方』について、
           具体的な tips を800字で書いて」
        → 具体的で深い内容

ステップ3: 「2つ目の見出しについて...」
        → (繰り返し)
```

**結果**:
各セクションが深く、具体的で、実用的な内容になる。

---

### ティーザー例2：コード生成の場合

**Before（70%の精度）**:

```text
依頼: 「認証システム全体を実装して」
結果: 動くけど、レビューで23個のコメント
```

**After（98%の精度）**:

```text
ステップ1: 「認証システムの型定義を、プロジェクト標準に沿って作成して」
        → 型定義ファイルが生成される

ステップ2: 「ログインエンドポイントを実装して。
           型は先ほどの定義を使用。
           エラーハンドリングはResult型で」
        → 標準に沿ったコードが生成される

ステップ3: 「ログイン試行を監査ログに記録する処理を追加して」
        → (繰り返し)
```

**結果**:
プロジェクト標準に沿った、レビュー可能なコード。

---

### ティーザー例3：画像生成の場合

**Before（70%の精度）**:

```text
依頼: 「会社のロゴを一発で完璧に作って」
結果: 10回修正しても「何か違う」
```

**After（98%の精度）**:

```text
ステップ1: 「ロゴのコンセプトを3つ提案して」
        → コンセプト案を確認・選択

ステップ2: 「選んだコンセプトで、カラーパレットを3つ提案して」
        → カラーを確認・選択

ステップ3: 「選んだコンセプトとカラーで、ロゴのラフを生成して」
        → (繰り返し、徐々に洗練)
```

**結果**:
ブランドにぴったりのロゴが段階的に完成。

---

### なぜ「小さく分ける」ことが効くのか？

それは、AIの**「見える範囲」に限界がある**からです。

```text
大きなお願い:
┌────────────────────────┐
│ 全体像（ぼんやり）      │
│   ↓                      │
│ 中間部分が見えない      │
│   ↓                      │
│ 推測が増える            │
│   ↓                      │
│ 精度70%                 │
└────────────────────────┘

小さく分けたお願い:
┌──────┐┌──────┐┌──────┐
│ 明確  ││ 明確  ││ 明確  │
│   ↓  ││   ↓  ││   ↓  │
│ 全部  ││ 全部  ││ 全部  │
│ 見える││ 見える││ 見える│
│   ↓  ││   ↓  ││   ↓  │
│ 98%  ││ 98%  ││ 98%  │
└──────┘└──────┘└──────┘
```

次の章では、この「見える範囲の限界」の正体を、
科学的に解き明かします。

スタンフォード大学の研究「**Lost in the Middle**」が示したのは、
LLM（大規模言語モデル）が**長い入力の中間部分を忘れやすい**
という驚くべき事実でした。

なぜAIは中間を忘れるのか？
どうすればこの限界を回避できるのか？

次章で、その答えを見つけましょう。

---

## 章末チェックリスト

この章の内容を実践に移すためのチェックリスト：

- [ ] 最近AIに「大きなお願い」をして微妙な結果になった経験を振り返る
- [ ] そのとき、何が「70%」で何が「足りない30%」だったか分析する
- [ ] 同じ仕事を「小さく分けたら」どうなるか想像してみる
- [ ] 次章で学ぶ「Lost in the Middle」問題への期待を持つ

---

## 次章への橋渡し

この章では、AIに「全部やって」と頼むと70%の完成度で止まってしまう
現象を見てきました。

ChatGPTでも、Claudeでも、画像生成でも同じ。
これは、AIの能力が低いのではなく、
**「見える範囲」に限界がある**からです。

次章では、この限界の正体を科学的に解き明かします。

スタンフォード大学の研究「**Lost in the Middle**」が示したのは、
LLM（大規模言語モデル）が長い入力の**「中間部分を忘れやすい」**
という驚くべき事実でした。

なぜAIは中間を忘れるのか？
コンテキストが長くなると、なぜ精度が下がるのか？
どうすればこの限界を回避できるのか？

次章で、その答えを見つけましょう。

---

## 画像生成プロンプト

### 画像1：章扉絵「70%問題」

**用途**: 扉絵（章の冒頭）
**配置**: 章タイトル直後

**プロンプト（日本語）**:
スプリットスクリーン形式のコンセプトイラスト。左側：ラップトップでAIインターフェースを使う興奮した表情の人物、親指を立てている、輝くAI画面。右側：同じ人物が画面を見て困惑し、やや不満げな表情、「ほぼ完璧だけど何か違う」という仕事を見ている。目立つプログレスバーが70%で表示。モダンでプロフェッショナルなスタイル、クリーンでミニマルな美学、テックブルーの配色にオレンジのアクセント。日本的なデザイン感覚 - すっきりとしてエレガント。ソフトな照明、デジタルアートスタイル。

**プロンプト（英語・画像生成AI用）**:

```text
A conceptual split-screen illustration showing the "70% problem" in AI
assistance. LEFT SIDE: Enthusiastic person at laptop with glowing AI
interface, excited expression, giving thumbs up. RIGHT SIDE: Same person
looking puzzled and slightly frustrated at screen showing work that's
"almost but not quite right". Prominent progress bar showing 70%
completion. Modern professional style, clean minimalist aesthetic,
tech-blue color scheme with hints of orange for contrast. Japanese
design sensibility - uncluttered, elegant. Soft lighting, digital art
style. --ar 16:9 --style professional --v 6
```

**スタイル指定**:

- アスペクト比: 16:9
- スタイル: ミニマル、プロフェッショナル
- カラー: テックブルー + オレンジアクセント
- トーン: 共感的、ユーモラス

---

### 画像2：コンテキストサイズと精度の関係グラフ

**用途**: 図解（本文中）
**配置**: 「なぜ『全部やって』は失敗するのか」セクション内

**プロンプト（日本語）**:
プロフェッショナルなインフォグラフィック。逆比例関係を示すグラフ。X軸は「タスクのサイズ」、マーカーは「小・中・大」。Y軸は「精度」で50%から100%まで。小さいタスクの98%から中規模の85%、大規模タスクの70%へと下降する滑らかな曲線。日本語ラベル付きのクリーンなデータビジュアライゼーション、テックブルーのグラデーション、ミニマルなグリッド。モダンなビジネスインテリジェンススタイル。

**プロンプト（英語・画像生成AI用）**:

```text
Professional infographic showing inverse relationship graph. X-axis
labeled "タスクのサイズ" (task size) with markers 小・中・大 (small,
medium, large). Y-axis labeled "精度" (accuracy) from 50% to 100%.
Smooth downward curve from 98% at small tasks, through 85% at medium,
to 70% at large tasks. Clean data visualization with Japanese labels,
tech-blue gradient, minimalist grid. Modern business intelligence style.
--ar 3:2 --style infographic --v 6
```

**スタイル指定**:

- アスペクト比: 3:2
- スタイル: インフォグラフィック、データビジュアライゼーション
- カラー: テックブルーのグラデーション
- トーン: 分析的、クリーン

---

### 画像3：大きいリクエスト vs 小さいリクエストの比較

**用途**: 図解（本文中）
**配置**: 「解決策のヒント」セクション内

**プロンプト（日本語）**:
サイドバイサイドの比較イラスト。左側：圧倒された人物、テキスト・コードシンボル・画像サムネイルが絡まった巨大な塊に埋もれている（1つの巨大なAIリクエストを表現）。混沌としてストレスフル。右側：同じ人物が冷静で整理されている、複数の小さな整った色分けされたボックスが整理されたレイアウトで浮かんでいる（分割されたリクエストを表現）。クリーンで管理された自信のある様子。日本のミニマル美学、プロフェッショナルなテックスタイル、落ち着いた青緑のパレット。

**プロンプト（英語・画像生成AI用）**:

```text
Side-by-side comparison illustration. LEFT: Person overwhelmed, buried
under single enormous tangled ball of text, code symbols, and image
thumbnails (representing one massive AI request). Chaotic, stressful.
RIGHT: Same person calm and organized, managing multiple small, neat,
color-coded boxes floating in organized layout (representing divided
requests). Clean, controlled, confident. Japanese minimalist aesthetic,
professional tech style, calming blue-green palette.
--ar 16:9 --style minimalist --v 6
```

**スタイル指定**:

- アスペクト比: 16:9
- スタイル: ミニマル、コンセプチュアル
- カラー: 青緑のパレット
- トーン: 対比的、解決策志向
