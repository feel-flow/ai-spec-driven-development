# 第1-1章　70%問題──「全部やって」が生む微妙さ

## この章で学ぶこと

- AIに大きなタスクを丸投げすると、なぜ70%程度の完成度で止まってしまうのかを理解する
- ChatGPT、Claude、画像生成AIなど、すべてのAIツールに共通する現象を把握する
- 「全部やって」と頼むことが、逆に精度を下げる理由を学ぶ

---

## 「ChatGPTに5000字書いてもらったら、なんか微妙だった」話

「AIに任せれば楽になる」

そう思って、ChatGPTにブログ記事を書いてもらったことはありませんか？

```text
プロンプト:
「リモートワークの生産性を高める方法について、
 5000字の包括的な記事を書いてください。」
```

数分後、ChatGPTは見事に5000字の記事を返してくれます。

読んでみると...

### 「悪くはないけど、なんか微妙」

- 一般的なヒントの羅列（「集中できる環境を作ろう」「タスク管理ツールを使おう」）
- どこかで見たような内容
- 独自の視点がない
- 深い洞察がない
- 自分のブランドらしさが全くない

「これ、そのままは使えないな...」

結局、大幅に手直しすることに。
期待していた「30分で記事完成」は幻想で、
「AI生成30分＋手直し2時間」というオチになりました。

これ、あなただけの経験ではありません。

---

## どのAIでも起きる「70%で止まる」現象

実は、この「悪くはないけど、なんか微妙」という感覚は、
**どのAIツールでも共通して発生**しています。

| AI用途              | 期待                        | 実際の結果                              | 精度   |
| ------------------- | --------------------------- | --------------------------------------- | ------ |
| ChatGPT文章生成     | 深い洞察のある5000字記事    | 表面的な内容、当たり障りのない文章      | ~70%   |
| Claude コード生成   | 完全な認証システム          | 動くが、セキュリティ標準が微妙          | ~70%   |
| Midjourney ロゴ     | ブランドイメージぴったり    | いい感じだけど、何か違う                | ~70%   |
| 市場調査            | 詳細な分析レポート          | 既知情報の羅列、独自視点なし            | ~70%   |

この「70%」という数字、偶然ではありません。

AIに**大きなタスクを丸投げ**すると、
だいたいこのくらいの完成度で止まってしまうのです。

### 例1：テキスト生成の場合

**依頼内容**:
「プロダクトマネジメントの実践ガイド」というタイトルで、
初心者向けの包括的な記事を5000字で書いてください。

**AIが返してきた内容**:

- プロダクトマネージャーの役割（一般論）
- アジャイル開発の基礎（教科書的）
- ユーザーリサーチの重要性（当たり前）
- ロードマップの作り方（抽象的）

**何が足りないか**:

- 実際のプロダクト開発での失敗談
- 具体的な意思決定のフレームワーク
- チーム間の調整で起きる実際の問題
- 定量データに基づく優先順位付けの方法

**結果**:
「間違ってはいないけど、これを読んでも実務では使えない」

---

### 例2：画像生成の場合

**依頼内容**:
「モダンなテクノロジースタートアップのロゴ。
 プロフェッショナルで記憶に残るデザイン。」

**Midjourneyが返してきたもの**:

- 確かに綺麗
- モダンな雰囲気はある
- テクノロジー感も出ている

**問題点**:

- どこかで見たようなデザイン
- 他の10社と区別がつかない
- ブランドの独自性がゼロ
- 会社のビジョンが伝わらない

**何度修正しても同じ**:
1回目の修正 → 「おしい...でも違う」
2回目の修正 → 「方向性は合ってきたけど...」
3回目の修正 → 「これじゃない感が消えない」

**10回修正した後**:
「もういい、デザイナーに頼もう」

---

### 例3：コード生成の場合

**依頼内容**:
「ユーザー認証システムを実装してください。
 JWT（JSON Web Token）、パスワードハッシュ、リフレッシュトークン、
 ログイン/ログアウト、パスワードリセット機能を含めて。」

**Claudeが生成したコード**:

- ちゃんと動く
- JWTも実装されている
- bcryptでハッシュ化もされている
- エンドポイントも揃っている

**でも、レビューで指摘された問題**:

1. ハッシュアルゴリズムが会社のセキュリティポリシーと異なる（argon2推奨なのにbcrypt）
2. エラーハンドリングが既存パターンと違う
3. 監査ログの実装がない（必須要件なのに）
4. レスポンス形式がAPI標準と不一致
5. テストコードが既存のテストフレームワークと異なる

**結果**:

- PR（プルリクエスト）に23個のコメントがついた
- 修正に2日かかった
- 主要部分を結局書き直した

「AIに頼んで時間を節約しようと思ったのに、逆に時間がかかってしまった...」

---

### 例4：調査・分析の場合

**依頼内容**:
「AI業界の最新トレンドを調査して、
 包括的なレポートを作成してください。」

**AIが返してきたレポート**:

- OpenAI、Google、Anthropicの動向（既知）
- 一般的な統計データ（どこでも見る）
- 予測可能な未来予測（ありきたり）

**何が足りないか**:

- ニッチなプレイヤーの動き
- 具体的な数値の裏付け
- 業界インサイダーの視点
- 実務への応用可能性
- 競合の具体的な戦略分析

**使えたのは**:
全体の30%くらい。残りは手動で調査し直し。

**結果**:

- 期待していた時間：30分
- 実際にかかった時間：3時間（手動調査＋AIの出力整理）
- 「最初から自分で調べた方が早かったかも...」

---

## なぜ「全部やって」は失敗するのか

ここまで見てきた例に、共通点があることに気づきましたか？

**すべて「大きなお願い」をしている**ことです。

- 「5000字の包括的な記事を書いて」
- 「完全な認証システムを実装して」
- 「プロダクトのロゴをデザインして」
- 「業界全体を調査して」

そして、すべて**70%くらいの完成度**で止まっています。

なぜでしょうか？

### AIには「見える範囲」に限界がある

人間でも、一度に大量の情報を処理しようとすると、
細部が曖昧になったり、重要なポイントを見落としたりします。

AIも同じです。

いや、AIの方が**この傾向はもっと強い**のです。

想像してみてください。

**小さなタスク**:
> 懐中電灯で照らした1畳の部屋
> → すべての角までくっきり見える

**大きなタスク**:
> 薄暗いライトで照らした10畳の部屋
> → 全体像はぼんやり見えるが、端の方は見えない

![タスクサイズと視認性の比較](./flashlight_comparison.png)

AIに大きなタスクを渡すと、こうなります:

![コンテキストサイズと精度の関係](./context_accuracy_chart.png)

これは単なる比喩ではありません。

2023年、スタンフォード大学のNelson F. Liuらの研究チームが、
LLM（大規模言語モデル）の驚くべき特性を発見しました。

論文「Lost in the Middle: How Language Models Use Long Contexts」[^1]で報告されたのが、「**Lost in the Middle**」問題です。

> **重要な発見**
>
> LLMは長い入力の「中間部分」を忘れやすい。
>
> 最初と最後はよく覚えているが、
> 中間に何があったかは曖昧になる。
>
> そして、入力が長くなるほど、
> この傾向は強くなる。

これが、「全部やって」が失敗する根本原因の1つです。

実は、AIには**もう1つの弱点**があります。2025年に発見された「Lost at the Beginning of Reasoning（推論の最初で迷子になる）」問題です。これは「熟考型AI」（推論モデル）に特有の弱点で、第2-2章で詳しく解説します。

どちらの弱点も、「**小さく分ける**」ことで解決できます。

---

### 大きなお願いが精度を下げるメカニズム

なぜ大きなお願いだと精度が下がるのか？

プロセスを分解してみましょう。

**あなたがAIに依頼**:
「包括的な記事を5000字で書いて」

**AIが処理する情報**:

1. タイトル（リモートワーク生産性）
2. トピック1（環境作り）
3. トピック2（ツール活用）
4. トピック3（時間管理）
5. トピック4（コミュニケーション）
6. トピック5（健康管理）
7. トピック6（メンタルケア）
... さらに多数

**AIの内部で起きていること**:

- すべてのトピックを「同時に」考慮しようとする
- でも、「見える範囲」に限界がある
- 中間のトピックは「ぼやける」
- 各トピックの深掘りができない
- 結果として、表面的な内容になる

**アウトプット**:
一般的で当たり障りのない内容（70%の完成度）

---

### 精度低下の具体的なパターン

#### パターン1：汎用化

**大きなお願い**:
「プロジェクト管理の完全ガイドを書いて」

**AIの思考**:
「プロジェクト管理は幅広いから、
 すべてのケースに当てはまるように書こう」

**結果**:
誰にでも当てはまるが、誰にも役立たない内容

---

#### パターン2：表面化

**大きなお願い**:
「認証システムを完全に実装して」

**AIの思考**:
「認証、認可、セッション、リフレッシュトークン...
 すべてを考慮しなきゃ」

**結果**:
それぞれの実装は動くが、深い考慮（セキュリティ、パフォーマンス、監査）がない

---

#### パターン3：推測の増加

**大きなお願い**:
「会社のロゴをデザインして」

**AIの思考**:
「モダンなテック企業なら、
 きっとこういうデザインが好きだろう」

**結果**:
推測に基づいた汎用的なデザイン（会社固有の要素ゼロ）

---

## 実際に起きる「微妙」の正体

「70%」という完成度が、実際のプロジェクトでどんな影響を与えるか、
3つのケーススタディで見ていきましょう。

### ケース1：市場調査レポート

**背景**:
スタートアップの戦略会議に向けて、
競合分析レポートが必要になった。

**依頼**:
「AI SaaS市場の競合分析レポートを作成して。
 主要プレイヤー、市場規模、トレンド、
 差別化ポイントを含めて。」

**AIが返してきたレポート**:

```markdown
# AI SaaS市場 競合分析レポート

## 市場規模
- 2023年: $XX billion
- 2025年予測: $YY billion
- CAGR（年平均成長率）: XX%

## 主要プレイヤー
1. OpenAI - ChatGPT Enterprise
2. Google - Vertex AI
3. Anthropic - Claude for Work
... (10社リスト)

## トレンド
- エンタープライズ導入が加速
- オンプレミス需要の増加
- 業界特化型AIの登場
```

**一見良さそうに見える。でも...**

戦略会議で使おうとしたら、こんな質問が飛んできた:

- 「OpenAIの直近の価格改定の影響は？」
  → レポートには載っていない

- 「中小規模の競合（SeriesA前後）で注目すべきは？」
  → 大手しか載っていない

- 「導入障壁は何？どう攻略する？」
  → 一般論しか書いていない

- 「実際のユーザーの不満点は？」
  → アンケート結果や口コミ分析がない

**結果**:
レポートの70%を作り直し。
結局、3日かけて独自調査を実施。

**何が悪かったのか**:
「包括的なレポート」という大きなお願いをしたため、

- 表面的な情報の羅列になった
- 戦略立案に必要な「深い洞察」がなかった
- 競合の「弱点」や「攻めどころ」が見えなかった

---

### ケース2：ユーザー管理機能の実装

**背景**:
SaaS（Software as a Service）プロダクトに新しいユーザー管理機能が必要になった。

**依頼**:
「ユーザー管理システムを実装してください。
 ユーザー登録、ログイン、権限管理、
 プロフィール編集、パスワードリセット機能を含めて。」

**AIが生成したコード**:

```typescript
// 600行のコードが生成された
// - 認証エンドポイント
// - ユーザーCRUD
// - 権限チェックミドルウェア
// - パスワードリセット機能
```

**一見完璧。でも、PRレビューで...**

**レビューコメント（抜粋）**:

1. ❌ セキュリティ: bcrypt使ってるけど、会社標準はargon2
2. ❌ エラーハンドリング: Result型使ってない（プロジェクト標準）
3. ❌ 監査ログ: ログイン試行の記録がない（コンプライアンス必須）
4. ❌ レート制限: ブルートフォース攻撃対策がない
5. ❌ セッション管理: 同時ログインの制御がない
6. ❌ API設計: レスポンス形式がプロジェクト標準と違う
7. ❌ データベース: マイグレーションファイルがない
8. ❌ テスト: E2E（End to End）テストがない、単体テストのカバレッジが不十分
9. ❌ ドキュメント: API docが自動生成されない形式
10. ❌ 型定義: 共通の型定義ファイルを参照していない

... さらに13個のコメント

**修正にかかった時間**:

- 当初の期待：「AIが書いてくれるから1日で終わる」
- レビュー＋修正：2日
- 再レビュー＋再修正：1日
- 主要部分の書き直し：2日
- **合計：5日**

**手動で書いた場合の見積もり**:
3日（最初からプロジェクト標準に沿って書く）

**結論**:
「AIに任せた方が遅かった」

---

### ケース3：プロダクトローンチの資料作成

**背景**:
新プロダクトのローンチに向けて、
マーケティング資料が必要になった。

**依頼**:
「新プロダクトのマーケティングプレゼン資料を作成してください。
 ターゲット顧客、課題、ソリューション、差別化要因、
 価格戦略を含む10-15枚のスライドで。」

**AIが作成した資料**:

```text
スライド1: タイトル
スライド2: 市場の課題（一般論）
スライド3: ソリューション概要
スライド4-7: 機能説明
スライド8: 競合比較（表形式）
スライド9: 価格プラン
スライド10: まとめ
```

**一見良さそう。でも、実際にチームでレビューすると...**

**問題点**:

1. **ビジュアルの一貫性がない**
   - スライドごとにデザインテイストが違う
   - ブランドガイドラインを無視

2. **メッセージが曖昧**
   - ターゲット顧客が「スタートアップ」としか書いていない
   - 具体的なペルソナがない（エンジニア？営業？経営者？）

3. **差別化が弱い**
   - 「高速」「簡単」「安全」という汎用的な言葉だけ
   - 競合と何が違うのか不明確

4. **データがない**
   - 「生産性が向上します」→ どのくらい？
   - 「コストを削減」→ 具体的に何%？

**修正の繰り返し**:

**1回目の修正依頼**:
「ターゲットをもっと具体的に。エンジニアリングマネージャー向けで。」

→ 変わったのはタイトルだけ。内容は汎用的なまま。

**2回目の修正依頼**:
「競合との違いをもっと明確に。APIの柔軟性が強みなんです。」

→ スライド8の競合比較表に「API柔軟性: ◎」が追加されただけ。

**3回目の修正依頼**:
「ブランドカラー（青＋オレンジ）を使って、デザインを統一して。」

→ デザインは変わったが、今度はフォントが読みにくくなった。

**10回目の修正**:
「もういい、デザイナーに頼もう」

---

## 章末チェックリスト

- [ ] 最近AIに「包括的に」「完全に」「全部やって」とお願いしたケースを思い出す
- [ ] その結果が「70%くらいの完成度」だったか振り返る
- [ ] 3つの精度低下パターン（汎用化・表面化・推測増加）のどれに該当したか分析する
- [ ] 「Lost in the Middle」問題を理解し、大きなタスクがなぜ精度低下を招くか説明できる
- [ ] AIには「もう1つの弱点」（第2-2章）があることを知っておく

---

<div class="column-box">

### 🛒 コラム：スーパーの買い物袋は1つで大丈夫？

**DJ町娘**：「今日は買い物いっぱいしちゃった！でも袋は1つでいいですよね✨」

**AI侍**：「本当に入るのか？」

**DJ町娘**：「大丈夫、大丈夫！えっと...牛乳、卵、トマト...あれ？パンが入らない...」

**AI侍**：「ふむ」

**DJ町娘**：「ちょっと待って、こう斜めにすれば...きゃあ！卵が割れそう！💦」

**AI侍**：「無理に詰め込もうとしておるな」

**DJ町娘**：「でももう詰めちゃったし...よいしょ、よいしょ...重い！こぼれる！トマトが落ちそう！」

（DJ町娘、両手で必死に袋を抱えて、大袈裟によろよろと歩く）

**DJ町娘**：「先生、助けて〜！😭」

**AI侍**：「ふふふ。欲張って1つの袋に全部詰めた結果じゃな。最初から**3つの袋に分けて**おけば...」

**DJ町娘**：「軽々と持てて、卵も割れない！」

**AI侍**：「その通り。AIも同じじゃ。大きな依頼1つ（70%成功）より、小さな依頼3つ（100%×3）の方が確実。これが『小さく分ける』戦略である」

**DJ町娘**：「買い物もAIも、欲張りは禁物なんですね！🛍️」

</div>

---

[^1]: Liu, Nelson F., et al. "Lost in the Middle: How Language Models Use Long Contexts." arXiv:2307.03172, 2023. [arXiv](https://arxiv.org/abs/2307.03172)
