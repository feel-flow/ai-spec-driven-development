# 新しい本の企画：AIを使う全ての人向けの思想編

## 確定事項

### タイトル
「**なぜAIは期待通りに動かないのか**」
── 小さく、でも余白を残して

### コンセプト
- **対象読者**：AIを使う全ての人（エンジニアに限らない）
- **分量**：80-120ページ
- **位置づけ**：姉妹編の「思想編」

---

## 核心のアイデア

### AIの限界と解決策
```
【現実】
AIに「全部やって」と頼む → 70%の完成度で止まる
コンテキスト量が大きくなる → 精度が下がる

【解決策：小さく使う】
小さく分けて渡す → コンテキストが小さい → 精度が上がる
70% → 90% → 98% と収束！
```

### 普遍的な原則
この原則は、AIを使う全ての場面に当てはまる：
- コードを書くとき
- 文章を作るとき
- 画像を生成するとき
- リサーチするとき
- アイデアを出すとき

---

## 繰り返し使うキーワード

| キーワード | 表現する側面 |
|-----------|-------------|
| **コンテキスト縮小戦略** | WHY：なぜ必要か（AIの限界に対応） |
| **スコープ収束パターン** | HOW：どうやるか（分けて→渡して→収束） |
| **AI精度エンジニアリング** | WHAT：目的は何か（AIの精度を意図的に設計） |

---

## 構成案（確定・7部構成）

### 第1部：なぜAIは期待通りに動かないのか？（20ページ）
- 「全部やって」と頼むと微妙になる現象
- ChatGPTでも、Claudeでも、画像生成でも同じ
- みんなが経験してる「なんか微妙」問題
- 大きなお願いほど曖昧になる

### 第2部：AIの「見える範囲」には限界がある（15ページ）
**【核心：Lost in the Middle問題】**
- 論文「Lost in the Middle: How Language Models Use Long Contexts」を引用
- LLMは「最初」と「最後」をよく覚えてる
- でも「中間」は忘れやすい
- コンテキストが長いほど、この傾向が強い
- → 大きなお願い = 中間が増える = 忘れる = 精度が落ちる
- → 小さく分ける = 中間がない = 全部覚える = 精度が上がる

### 第3部：細かく指示する ── 精度を上げる（25ページ）
**【対比の前半：精度重視のアプローチ】**
- 分けて渡す → 精度が上がる
- 一度に全部求めない
- 小さな成功を積み重ねる
- 「スコープ収束パターン」の紹介
- 「**二段階AI活用**」
  - AIに直接結果を出させるのではなく、ツール/コードを作らせる
  - 例：AIにテストさせる → AIにテストコードを書かせる
  - 例：AIに回答を求める → AIに回答を導くツールを作らせる
  - AIの出力を検証可能な形にする → 精度向上

### 第4部：曖昧にする ── 推論を引き出す（15ページ）
**【対比の後半：推論重視のアプローチ】**
- 細かく指定する → コンテキストは節約されるが、推論の邪魔をする
- 曖昧に指定する → 推論の幅が広がるが、的外れになるリスクも
- 「〜と思うけど、どう思う？」で余地を残すテクニック
- 目的に応じた使い分け：
  - 実行させたい時 → 具体的に（精度重視）
  - 考えさせたい時 → 曖昧に（推論重視）
- AIに「提案してもらう」「壁打ち相手になってもらう」場面での活用

### 第5部：よくある失敗とその対処法（20ページ）
**Before/After形式で失敗パターンと解決策を見せる**
- パターン1：全部一度に頼む → 分けて頼む
  - 例：「5000字で書いて」→「見出し5つ」→「各800字」
- パターン2：曖昧なまま大きく頼む → 要素を分けて具体的に
  - 例：「いい感じのロゴ」→「シンプル」「青系」「テック感」
- パターン3：AIに直接判断させる → 検証可能な形で出力させる
  - 例：「テストして」→「テストコードを書いて」→実行
- パターン4：修正を一度に全部頼む → 1つずつ確認しながら
  - 例：「10個直して」→「1つ直して確認」を繰り返す

### 第6部：VSCodeでの実践（25ページ）
- ファイル分割の考え方
- どう分けるか
- AIへの渡し方
- この本の壁打ち例（メタな紹介）

### 第7部：AIと人間の新しい役割分担（10ページ）
- 人間の仕事は「分けること」になる
- AIは「小さいことを正確に」
- 組み合わせで大きな成果を出す
- 姉妹編「AI仕様駆動開発」への橋渡し

---

## 2冊の関係性：姉妹編

```
📘 新しい本（思想編・AI全般向け）80-120ページ
「なぜAIは期待通りに動かないのか」
   ── 小さく、でも余白を残して
   │
   │ AIを使う全ての人向け
   │ 普遍的な原則を語る
   │ 「精度」と「推論」の両立を説く
   │
   ▼
📗 既存の本（実践編・開発者向け）
「AI仕様駆動開発」
   │
   │ エンジニア向け
   │ 具体的な7文書、ツール、チーム導入
```

---

## 想定読者

- AIを使う全ての人
- ChatGPT/Claude使う人
- 画像生成AI使う人
- ビジネスでAI活用したい人
- 「AIがうまく使えない」と感じてる人
- エンジニアだけでなく、一般のユーザーも対象

---

## 引用候補の論文・データ

### 必須で引用
- **Lost in the Middle: How Language Models Use Long Contexts** (2023, Stanford)
  - LLMが長いコンテキストの中間を忘れやすい問題を実証
  - 第2部の核心として使用

### 引用候補（執筆時に最新を調査）
- **Attention Is All You Need** (2017, Google)
  - Transformerの基礎論文、コンテキストの仕組みを説明するため
- **Scaling Laws for Neural Language Models** (2020, OpenAI)
  - モデルサイズとコンテキスト長の関係
- **Context Length Extension** 関連の最新論文
  - 2024-2025年の最新研究を執筆時に調査
- **Prompt Engineering** 関連のベストプラクティス
  - 「分けて渡す」の効果を示すデータ

### 実績データ
- 姉妹編「AI仕様駆動開発」からの実績データを引用
  - コード生産性115〜460倍
  - PRマージ率98%
  - コードレビュー工数削減97%
