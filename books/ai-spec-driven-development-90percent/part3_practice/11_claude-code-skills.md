# 第11章　ツール実装（前編）：Claude Code Skillsで"仕様駆動"を自動化する

## この章で学ぶこと

- Claude Code Skillsの考え方と設計方法
- 仕様駆動開発を支援するスキルの実装例
- pr-review-toolkit（公式プラグイン）の活用方法

---

## 読者へのメッセージ

本章と次章（第12章）では、**Claude Code**と**GitHub Copilot**の両方を取り上げます。

どちらのツールでも、仕様駆動開発を支援する**同等のエージェント機能**を利用できます。普段お使いのツールに合わせて、該当する章を参照してください。

| 章 | 対象ツール | 内容 |
|----|-----------|------|
| 本章（第11章） | Claude Code | Skills、pr-review-toolkit |
| 次章（第12章） | GitHub Copilot | Skills（共通）、カスタムエージェント |

**重要な違い**:

| 観点 | Claude Code | GitHub Copilot |
|------|-------------|----------------|
| プラグイン | pr-review-toolkitなど公式提供済み | なし（自作が必要） |
| 準備の手間 | すぐに使える | テンプレートを導入 |
| カスタマイズ | Skills/Agentsファイル | Skills（共通）+ `.github/agents/*.md` |

---

## Skillsの考え方

### Skillsとは

Claude CodeのSkillsは、**特定のワークフローをモジュール化**したものです。

繰り返し行う作業を「スキル」として定義しておくことで：

- 毎回同じ指示を書かなくて済む
- チーム全体で統一された方法で作業できる
- プロジェクト横断で再利用できる

### スキルの基本構造

```markdown
# スキル名

## 説明
このスキルが何をするか

## トリガー
どんなときにこのスキルを使うか

## 実行手順
1. ステップ1
2. ステップ2
3. ステップ3

## 入力
- 必要な情報1
- 必要な情報2

## 出力
- 生成されるもの
```

### スキルを作るべきタイミング

「どの作業をスキル化すべきか」という判断は難しいものです。以下の基準を参考にしてください。

**スキル化すべき作業の条件**:

1. **繰り返し発生する**：週に3回以上同じ作業をしている
2. **手順が定型化できる**：毎回ほぼ同じステップを踏む
3. **ミスが起きやすい**：手順を忘れたり、漏れが発生したりする

逆に、スキル化しないほうがよいケースもあります。

**スキル化を避けるべきケース**:

- 頻度が低い作業（月に1回程度）：スキルを作るコストに見合わない
- 毎回判断が異なる作業：定型化が難しく、スキルの柔軟性が足りなくなる
- 一度きりの作業：使い回せないスキルは無駄

まずは「この作業、もう3回目だな」と感じたらスキル化を検討しましょう。最初から完璧なスキルを作る必要はありません。簡単なスキルから始めて、使いながら改善していく方が効率的です。

---

## 仕様駆動を支援するスキル例

### スキル1：プロジェクト初期化

```markdown
# spec-init

## 説明
7文書構成を新規プロジェクトに導入する

## トリガー
「7文書を初期化して」「spec-initを実行して」

## 実行手順
1. docs/ディレクトリを作成
2. 7つのテンプレートファイルを生成
3. MASTER.mdにプロジェクト情報を記入
4. .claude/settings.jsonにドキュメントパスを設定

## 入力
- プロジェクト名
- 技術スタック（言語、フレームワーク、DB）
- 簡単な説明

## 出力
- docs/MASTER.md
- docs/PROJECT.md
- docs/ARCHITECTURE.md
- docs/DOMAIN.md
- docs/PATTERNS.md
- docs/TESTING.md
- docs/DEPLOYMENT.md
```

### スキル2：Issue作成支援

```markdown
# create-issue

## 説明
仕様駆動に適したIssueを作成する

## トリガー
「Issueを作って」「タスクをIssue化して」

## 実行手順
1. ユーザーから機能の概要をヒアリング
2. 関連する仕様文書（DOMAIN.md, ARCHITECTURE.md）を参照
3. 受け入れ基準を具体化
4. 技術的制約を洗い出し
5. スコープ外を明確化
6. Issue形式で出力

## 入力
- 機能の概要
- 関連する既存機能（あれば）

## 出力
- Issue本文（Markdown形式）
- 関連文書へのリンク
```

### スキル3：文書検証

```markdown
# validate-docs

## 説明
7文書の整合性と完全性を検証する

## トリガー
「ドキュメントを検証して」「validate-docs」

## 実行手順
1. 全文書のFrontmatterを検証
2. 内部リンクの有効性を確認
3. 用語の統一性をチェック
4. 文書間の参照整合性を確認
5. MASTER.mdの索引が最新か確認
6. 問題点をレポート

## 入力
- 検証対象のディレクトリ（デフォルト: docs/）

## 出力
- 検証結果レポート
- 修正が必要な箇所のリスト
```

### スキル4：影響度評価

```markdown
# assess-impact

## 説明
文書変更の影響度を評価する

## トリガー
「この変更の影響度は？」「assess-impact」

## 実行手順
1. 変更内容を分析
2. 影響を受ける文書を特定
3. 影響を受けるコードを特定
4. 影響度（LOW/MEDIUM/HIGH）を判定
5. 対応チェックリストを生成

## 入力
- 変更内容の説明
- または変更対象の文書パス

## 出力
- 影響度（LOW/MEDIUM/HIGH）
- 影響を受ける文書リスト
- 対応チェックリスト
- HIGH の場合はADRテンプレート
```

### スキル5：コミット前チェック

```markdown
# pre-commit-check

## 説明
コミット前に仕様準拠を確認する

## トリガー
コミット時に自動実行（huskyフック）

## 実行手順
1. 変更されたファイルを取得
2. 関連する仕様文書を特定
3. 仕様との整合性を確認
4. PATTERNS.mdのルールに違反していないか確認
5. MASTER.mdの更新が必要か判断
6. 問題があれば警告

## 入力
- ステージングされたファイル

## 出力
- チェック結果（OK/警告/エラー）
- 警告・エラーの詳細
```

### スキル同士を組み合わせる

個々のスキルは単独でも便利ですが、組み合わせることでより強力なワークフローを構築できます。

#### 典型的なワークフロー例

プロジェクト開始から日々の開発まで、スキルを連携させた流れを示します。

```text
プロジェクト開始時:
  spec-init → validate-docs → create-issue
  （初期化 → 検証 → 最初のIssue作成）

機能開発時:
  create-issue → [AIで実装] → pre-commit-check → assess-impact
  （Issue作成 → 実装 → コミット前チェック → 影響度評価）

リリース前:
  validate-docs → multi-review → assess-impact
  （文書検証 → 多視点レビュー → 影響度の最終確認）
```

#### スキル連携のポイント

スキルを連携させるときは、前のスキルの出力が次のスキルの入力になるように設計します。

例えば、`create-issue`が出力する「関連文書へのリンク」は、AIが実装するときのコンテキストになります。また、`assess-impact`が出力する「影響を受ける文書リスト」は、`validate-docs`でチェックすべき対象になります。

このように、スキル間でデータが自然に流れる設計にすると、手動での情報の受け渡しが減り、ワークフロー全体が効率化します。

---

## サブエージェントによる多視点レビュー

### なぜ多視点が必要か

1人のレビュワー（人間でもAIでも）には盲点があります。

**多視点レビュー** は、異なる観点を持つ複数のエージェントが同時にレビューすることで、盲点をカバーします。

### レビュワーエージェントの例

#### セキュリティレビュワー

```markdown
# security-reviewer

## 役割
セキュリティ観点でコードをレビューする

## 確認観点
- 認証・認可の実装
- 入力検証の網羅性
- 機密データの取り扱い
- 依存ライブラリの脆弱性
- ログ出力に機密情報が含まれていないか

## 出力形式
## セキュリティレビュー結果

### 重大な問題
- [ファイル:行] 問題の説明

### 警告
- [ファイル:行] 懸念点の説明

### 推奨事項
- 改善提案
```

#### パフォーマンスレビュワー

```markdown
# performance-reviewer

## 役割
パフォーマンス観点でコードをレビューする

## 確認観点
- N+1クエリの有無
- 不要なループ処理
- メモリ効率
- キャッシュ戦略
- 非同期処理の適切性

## 出力形式
## パフォーマンスレビュー結果

### 問題
- [ファイル:行] 問題の説明と推定影響

### 最適化提案
- 改善案と期待される効果
```

#### アーキテクチャレビュワー

```markdown
# architecture-reviewer

## 役割
既存アーキテクチャとの整合性をレビューする

## 確認観点
- レイヤー構成の遵守
- 依存関係の方向
- 責務の分離
- ARCHITECTURE.mdとの整合性
- PATTERNS.mdのパターン適用

## 出力形式
## アーキテクチャレビュー結果

### 違反
- [ファイル] 違反内容と参照すべき文書

### 改善提案
- よりよい設計案
```

### 複数エージェントの統合実行

```markdown
# multi-review

## 説明
複数のレビュワーエージェントを並行実行する

## トリガー
「PRをレビューして」「multi-review」

## 実行手順
1. 変更ファイルを取得
2. 以下のエージェントを並行実行
   - security-reviewer
   - performance-reviewer
   - architecture-reviewer
3. 結果を統合してレポート

## 出力
## 統合レビュー結果

### セキュリティ
[security-reviewerの結果]

### パフォーマンス
[performance-reviewerの結果]

### アーキテクチャ
[architecture-reviewerの結果]

### 総合判定
[Approve / Request Changes / Comment]
```

---

## pr-review-toolkit（公式プラグイン）

Claude Codeには、PRレビュー専用の公式プラグイン「**pr-review-toolkit**」が提供されています。6つの専門エージェントを組み合わせた包括的なレビューシステムです。

### 使い方

```bash
# すべてのレビューを実行
/pr-review-toolkit:review-pr

# 特定のアスペクトのみ
/pr-review-toolkit:review-pr tests errors

# すべてを並列実行
/pr-review-toolkit:review-pr all parallel
```

### 6つの専門エージェント

| エージェント | 役割 | 主な検出対象 |
|-------------|------|-------------|
| code-reviewer | コード品質 | CLAUDE.md違反、バグ、スタイル問題 |
| silent-failure-hunter | エラーハンドリング | 空のcatchブロック、沈黙する失敗 |
| code-simplifier | 簡潔化 | ネスト過多、冗長コード |
| comment-analyzer | コメント品質 | 不正確なコメント、コメント腐れ |
| pr-test-analyzer | テスト分析 | テスト不足、エッジケース漏れ |
| type-design-analyzer | 型設計 | カプセル化不足、不変性の問題 |

### code-reviewerの信頼度スコア

code-reviewerは検出した問題に0-100の信頼度スコアを付与し、**80以上のみを報告**します。

| スコア | 意味 | 報告 |
|--------|------|------|
| 0-25 | 誤検出または既存の問題 | しない |
| 26-50 | マイナー（ガイドラインに明記なし） | しない |
| 51-79 | 有効だが低影響 | しない |
| 80-90 | 重要な問題 | する |
| 91-100 | クリティカル | 必ずする |

この仕組みにより、ノイズの少ない高品質なレビュー結果が得られます。

---

## ドメイン固有のナレッジをレビュースキルに昇格させる

### レビューループが示すナレッジの欠落

ここまで紹介したように、Issueベースでスコープを絞り、pr-review-toolkitで品質を担保する。この仕組みは強力ですが、**ビジネスロジックや組織独自の仕様**に関する指摘は防げません。

たとえば、こんな指摘が繰り返されます。

- 「決済金額の丸め処理は、通貨ごとに異なるルールを適用すること」
- 「社内APIのレスポンスには必ず`request_id`を含めること」
- 「個人情報を含むログは、マスキング処理を通してから出力すること」

これらはプロジェクト固有のルールであり、汎用的なコードレビューツールではカバーできません。同じ指摘を何度も受けてしまうのは、**ナレッジが仕組みに反映されていない**からです。

### 3回繰り返されたらスキル化のサイン

第10章のステップ6「指摘をナレッジ化」では、レビューで得た知見をPATTERNS.mdに蓄積する方法を紹介しました。しかし、PATTERNS.mdへの記載だけでは、AIが毎回それを参照してくれる保証はありません。

**同じ種類の指摘が3回程度繰り返されたら、それはスキル化すべきサインです。**

PATTERNS.mdへの蓄積は「知識の記録」、レビュースキルへの昇格は「知識の自動適用」。この違いが、レビューループを断ち切る鍵になります。

### pr-review-toolkitだけでは足りない理由

pr-review-toolkitは汎用的なコードレビューを提供する公式プラグインです。コードの品質、セキュリティ、エラーハンドリングなど、どのプロジェクトにも共通する観点をカバーしてくれます。

しかし、以下のような**ドメイン固有の観点**は守備範囲外です。

- 業界特有の規制やコンプライアンス要件
- 社内で定めたAPI設計規約
- ビジネスロジックの整合性ルール
- チーム固有のアーキテクチャ方針

そこで、**pr-review-toolkit（汎用）＋カスタムスキル（ドメイン固有）の二段構え**でレビュー体制を構築します。

### ドメイン固有レビュースキルの作り方

カスタムレビュースキルは、通常のスキルと同じ仕組みで作成できます。以下はテンプレート例です。

```markdown
---
description: >
  決済ドメインのコードレビュー。決済関連のファイルを変更したとき、
  金額計算・通貨処理・トランザクション管理の観点でレビューを実行する。
---

# 決済ドメインレビュー

## レビュー対象
変更されたファイルのうち、決済ドメインに関連するコードを対象にレビューしてください。

## チェック観点

### 金額計算
- 浮動小数点演算を使っていないか（Decimalまたは整数演算を使用すること）
- 通貨ごとの小数点以下桁数ルールに従っているか
- 丸め処理の方向（切り捨て/切り上げ/四捨五入）が仕様と一致しているか

### トランザクション管理
- 決済処理は冪等性キーを使用しているか
- タイムアウト時のリトライ処理が実装されているか
- 部分的な失敗時のロールバック処理があるか

### コンプライアンス
- PCI DSSに関わるデータがログに出力されていないか
- カード番号のマスキング処理が適用されているか

## 出力形式
問題を発見した場合、以下の形式で報告してください：
- **ファイル名と行番号**
- **問題の内容**（なぜ問題なのかを簡潔に）
- **修正案**（具体的なコード例があれば提示）
```

このスキルを`.claude/commands/`や`.claude/skills/`に配置することで、「決済関連のPRを出すときはドメインレビューも実行する」というワークフローが成立します。

### AIに「スキル化すべきか」の判断を委ねる

「どの指摘をスキル化すべきか」を人間が毎回判断する必要はありません。AIに委ねてしまいましょう。

たとえば、レビューで同じパターンの指摘が繰り返されたとき、AIが次のように提案してくれる流れが理想的です。

> 「この指摘パターンは過去3回のPRでも同様のフィードバックがありました。ドメイン固有のレビュースキルとして定義しませんか？」

実際にClaude Codeを使っていると、こうした提案は自然に発生します。重要なのは、その提案を受けたときに「**はい、スキルにしてください**」と指示するだけでよいということです。AIがスキルファイルを生成してくれます。蓄積の判断も、スキルの作成も、AIとの協働で完結します。

### 二段構えのレビュー体制

最終的に目指す姿は、以下のような二段構えのレビュー体制です。

| レイヤー | 担当 | 観点 |
| --- | --- | --- |
| 汎用レビュー | pr-review-toolkit | コード品質、セキュリティ、エラーハンドリング |
| ドメインレビュー | カスタムスキル | ビジネスルール、規約、コンプライアンス |

プロジェクトが進むにつれて、カスタムスキルは少しずつ増えていきます。「決済ドメインレビュワー」「社内API規約チェッカー」「個人情報保護チェッカー」など、チームのナレッジがスキルとして蓄積されていきます。蓄積が進むほど、レビューの品質は自動的に向上します。

---

## スキルの設計ポイント

### 1. 起動条件（description）の重要性

スキルは「いつ起動するか」が重要です。

```markdown
## 良いdescription
「7文書を初期化したいとき」「新規プロジェクトでspec-initを実行」

## 悪いdescription
「プロジェクト設定」（曖昧すぎる）
```

明確な起動条件により、ユーザーが意図したタイミングでスキルが発動します。

### 2. 入力の明確化

スキルに必要な入力を明確にします。

```markdown
## 入力
- プロジェクト名（必須）：リポジトリ名と同じ
- 技術スタック（必須）：言語、フレームワーク、DBを列挙
- 説明（任意）：1〜2文で概要
```

### 3. 冪等性

スキルは何度実行しても同じ結果になるように設計します。

```markdown
## 冪等性の確保
- ファイルが存在する場合は上書きしない（または確認する）
- 部分的に実行された場合も再実行で完了する
```

### 4. エラーハンドリング

失敗時の動作を定義します。

```markdown
## エラー時の動作
- 途中で失敗した場合、完了したステップを報告
- ロールバックが必要な場合は手順を提示
- 再実行方法を案内
```

### うまくいかなかったスキルの事例

スキル設計で実際に起きた失敗例を紹介します。同じ轍を踏まないための参考にしてください。

#### descriptionが曖昧で誤発動

あるチームが「code-review」というスキルを作りました。descriptionを「コードをレビューする」と書いたところ、「このコードをレビューして」以外にも、「このコードの意味を教えて」「このコードのバグを探して」など、意図しないタイミングで発動するようになりました。

解決策として、descriptionを「PRのコード変更をPATTERNS.mdに基づいてレビューする」と具体化しました。「PRの」「PATTERNS.mdに基づいて」という限定条件を入れることで、意図したタイミングでのみ発動するようになりました。

#### 入力が複雑すぎて使われない

別のチームが「full-spec-check」というスキルを作りました。入力として「対象ディレクトリ」「チェックレベル（厳密/標準/緩め）」「除外パターン」「レポート形式」「通知先」の5つを要求していました。

結果、誰も使いませんでした。毎回5つの入力を指定するのが面倒で、「手動でチェックした方が早い」となったのです。

解決策として、入力を「対象ディレクトリ」だけにし、他はデフォルト値を持つオプションにしました。「90%のケースはデフォルトで十分」という設計に変えたところ、利用率が上がりました。

#### 粒度が大きすぎて柔軟性がない

「deploy-all」というスキルは、テスト実行→ビルド→デプロイ→通知をすべて一気に実行するものでした。しかし、「テストだけ実行したい」「ビルドまでで止めたい」というケースに対応できず、結局使われなくなりました。

解決策として、「run-tests」「build」「deploy」「notify」に分割し、必要な組み合わせで使えるようにしました。さらに、よく使う組み合わせを「deploy-standard」としてまとめることで、利便性と柔軟性を両立しました。

---

## 章末チェックリスト（Claude Code ユーザー向け）

- [ ] プロジェクトで繰り返している作業を洗い出す
- [ ] 最もよく使う作業をスキル化する
- [ ] description（起動条件）を明確に書く
- [ ] pr-review-toolkitプラグインを導入する
- [ ] `/pr-review-toolkit:review-pr` をPR前に実行する習慣をつける
- [ ] 複数視点レビューの導入を検討する
- [ ] 必要に応じてカスタムスキルを作成する

---

## 🥷 AI侍道場 - ツールは手段、目的は価値

![AI侍道場：ツールは手段、目的は価値](../images/ch11-ai-samurai-dojo.png)

---

### 🗡️ AI侍の秘伝書

ツールに振り回されず、本質を守る3つの極意を授ける。

#### 秘伝その1：ツールは「加速装置」と心得よ

ツールは仕事を「作る」のではない。**「加速する」**ものだ。

- ❌ 悪い：ツールがあるから仕様を書かない
- ✅ 良い：仕様があるから、ツールで加速できる

ツールは**0→1を作るものではなく、1→10を加速するもの**である。

#### 秘伝その2：「繰り返し」をツール化せよ

ツール化すべきは、**毎回同じことを繰り返している作業**だ。

良いツール化の例：
- ✅ PRごとに必ず実行するレビュー
- ✅ 毎回書いているテストの雛形
- ✅ リリース前に必ず確認するチェックリスト

悪いツール化の例：
- ❌ 1回しか使わない作業
- ❌ 毎回異なる判断が必要な作業
- ❌ ツールより手動の方が早い作業

**繰り返し**がツール化の目印である。

#### 秘伝その3：ツールに「思考」を委ねるな

ツールは判断を**支援**するが、**代行**はできぬ。

- ✅ ツールが指摘 → 人間が判断（良い）
- ❌ ツールが指摘 → そのまま修正（危険）

例：
- ツールが「このコードは複雑すぎる」と指摘
- → **人間が**「本当に複雑か？必要な複雑さか？」を判断
- → 判断した上で、修正するか決める

**最終判断は必ず人間が下せ**。

---
