# はじめに

## 「AIに任せる開発なんて無理」の正体

「AIにコードを書かせる？ 結局、手直しに時間がかかって意味ないよ」

エンジニアの間でよく聞く声です。Claude Code、GitHub Copilot、Cursor——AIコーディングツールは確かに進化しています。しかし、多くの開発現場では、こんな悩みが絶えません。

- AIが生成したコードが、既存のアーキテクチャと全く合わない
- PRが巨大になりすぎて、レビューが不可能になる
- 「なぜこう実装したのか」が分からず、修正に余計な時間がかかる
- 何度も同じような間違いを繰り返す

これらの問題を経験すると、「やっぱりAIは信用できない」という結論に至りがちです。

しかし、**本当の問題はAIの能力ではありません**。

問題は、AIに渡している「入力」——つまり**スコープの曖昧さ**——にあります。

---

## 実際に効果はあるのか？——現場のデータ

「理屈はわかった。でも本当に効果があるのか？」

そう思う方のために、私が関わったプロジェクトでの計測結果を紹介します。

RAGチャットボットの機能実装において、Issue駆動でAIに開発を任せた結果です。

| 指標 | 結果 |
|------|------|
| コード生産性 | 業界平均（50〜200行/日）の**115〜460倍** |
| PRマージ率 | **98%**（321件中315件） |
| コードレビュー工数 | **97%削減**（人間は全体の3.3%のみ担当） |

※ これは開発工程全体ではなく、一部機能実装における統計データです。

ポイントは、**品質を落とさずに**この生産性を実現したことです。98%のPRがそのままマージされている事実が、それを証明しています。

詳細なレポートはこちら：[AI駆動開発レポート](https://feelflow.co.jp/report/ai-agent-development-report20251201/)

では、どうやってこの結果を出したのか？——それが本書で解説する「3つの戦略」です。

---

## 結論を先に言います：3つの戦略がすべて

私が実際にAI駆動開発を実践してきた経験から、**効く戦略は3つだけ** です。

### 戦略1：Issueでスコープを絞る（コンテキストエンジニアリング）

**これが最も重要です。**

「ログイン機能を作って」と指示すると、AIは迷います。認証方式は？エラーハンドリングは？既存コードとの整合性は？——書かれていないことを推測し、ほぼ確実にズレた実装をします。

解決策はシンプルです。**Issueを作り、スコープを絞る**。

```
❌ 悪い例：「認証機能を実装して」

✅ 良い例：
Issue #42: JWTトークン検証ミドルウェアの実装
- 受け入れ基準：
  - Authorization ヘッダーからBearerトークンを抽出
  - トークンの署名検証と有効期限チェック
  - 検証失敗時は401を返す
- 制約：
  - 既存の authMiddleware.ts を拡張
  - エラーレスポンスは errors/auth.ts の形式に従う
```

Issueを書く行為は、**コンテキストエンジニアリング**そのものです。AIに「何をすべきか」「何をすべきでないか」を明示することで、推測の余地を排除します。

スコープが絞られていれば、AIは迷わない。迷わなければ、バグは生まれない。

### 戦略2：PRは70%の完成度でいい

完璧を求めてはいけません。

AIが書いたコードをPRに出す時点では、**70%の完成度** だと思ってください。これは妥協ではなく、**設計された戦略** です。

なぜか？

レビューを受けることで、スコープがさらに狭まります。

- 「この関数、責務が2つ混ざってるね」→ 分割
- 「エッジケースのテストが足りない」→ 追加
- 「命名がプロジェクトの慣習と違う」→ 修正

レビュー指摘に基づいてAIに再実装させると、**指摘内容がそのままコンテキストになる**ため、より正確なコードが生成されます。

```
レビュー指摘：「validateUser関数、バリデーションと永続化が混ざってる」
↓
AIへの指示：「validateUser関数を、バリデーション専用のvalidateUserInput関数と、
             永続化専用のpersistUser関数に分割して」
↓
結果：明確な責務分離が実現
```

**レビュー→再レビュー→完成** という反復が、スコープを収束させ、精度を上げていきます。

### 戦略3：指摘をナレッジ化する

同じ指摘を何度も受けていませんか？

- 「またエラーハンドリングが漏れてる」
- 「テストのモック設定が毎回違う」
- 「import文の順序がバラバラ」

これらは**AIに事前に教えておくべき知識** です。

指摘が多かった場合、そのナレッジをまとめて「次回どうやったら指摘されないか」を仕組み化します。

**具体的な手段：**

1. **静的解析の強化**
   - ESLint/Prettierルールの追加
   - カスタムルールで頻出パターンを検出

2. **pre-commitフックでAIレビュー**
   ```bash
   # .husky/pre-commit
   claude-code review --staged --rules .review-rules.md
   ```

3. **サブエージェントによる多視点レビュー**
   - セキュリティ視点のレビュワーエージェント
   - パフォーマンス視点のレビュワーエージェント
   - 既存コード整合性チェックのエージェント

指摘を受ける→ナレッジ化→自動チェックに組み込む→次回から指摘されない。

このサイクルを回すことで、AIの出力品質は**プロジェクト固有の文脈を学習**し、継続的に向上します。

---

## この3つを支える基盤：7文書構成

上記の3戦略を効果的に運用するには、**AIが参照できる仕様の基盤** が必要です。

それが、本書で紹介する**7文書構成** です。

| 文書 | 役割 | 戦略との関係 |
|------|------|--------------|
| MASTER.md | プロジェクト索引 | AIが迷子にならない地図 |
| PROJECT.md | ビジョンと要件 | Issueの背景を示す |
| ARCHITECTURE.md | システム設計 | 制約を明示する |
| DOMAIN.md | ビジネスロジック | ルールの唯一の置き場 |
| PATTERNS.md | 実装パターン | ナレッジの蓄積先 |
| TESTING.md | テスト戦略 | レビュー基準を定義 |
| DEPLOYMENT.md | 運用手順 | リリース可能性を定義 |

Issueを書くとき、ARCHITECTURE.mdの制約を参照する。
レビューで指摘されたパターンは、PATTERNS.mdに蓄積する。
テストの書き方で揉めたら、TESTING.mdを更新する。

**仕様が整っていれば、3つの戦略はスムーズに回ります。**

---

## 本書の読み方

本書は5部構成になっています。

**第1部「なぜAI任せは失敗するのか」** では、AI活用が失敗する本当の原因を分析します。「AIが悪い」のではなく「スコープが曖昧」であることを理解していただきます。

**第2部「結論：仕様が9割」** では、7文書構成の全体像を提示します。各文書の役割と、3つの戦略との接続を解説します。

**第3部「実践ワークフロー」** では、Issueベースの開発フロー、70%完成度でのPR運用、ナレッジ蓄積の具体的な手順を示します。

**第4部「現場FAQ」** では、懐疑的なエンジニアからの質問に答えます。「結局人間が全部書くのでは？」「品質は担保できるのか？」

**第5部「組織に展開する」** では、個人の取り組みをチーム標準に広げる方法を解説します。

---

## さあ、始めましょう

AIコーディングツールは、正しく使えば圧倒的な生産性をもたらします。

しかし、「正しく使う」とは何か？

**スコープを絞り、70%で出し、指摘をナレッジ化する。**

この3つの戦略と、それを支える7文書構成。

「AIに任せる開発なんて無理」を「AIに任せたら、本当に楽になった」に変える。

そのための旅を、一緒に始めましょう。
