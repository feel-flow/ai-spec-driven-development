# 第11章　品質・セキュリティ・責任の所在

## この章で学ぶこと

- 「AIが書いたコード」の責任の考え方
- テスト戦略を先に固める意味
- 監査可能性を確保する仕組み

---

## 「AIが書いたコード」の責任は誰にあるか

### よくある懸念

- 「AIが書いたコードにバグがあったら、誰の責任？」
- 「セキュリティホールがあったら？」
- 「本番障害が起きたら？」

これらの懸念は当然です。しかし、**責任の所在は明確** です。

### 責任は「承認した人」にある

```
AI生成コード → レビュー → 承認 → マージ → デプロイ
                  ↑          ↑
               レビュワー    責任者
```

AIはツールです。ツールが出力したものを**承認した人間に責任があります**。

これは、IDEの自動補完やコードフォーマッタと同じ考え方です。

- Prettierが変なフォーマットをしても、Prettierの責任ではない
- 設定した人、承認した人の責任

### 責任を取れる状態を作る

責任を取るためには、以下が必要です。

1. **レビュー可能であること**
   - コードが理解できる粒度であること
   - 変更理由が追跡できること

2. **テストがあること**
   - 動作が検証されていること
   - 回帰テストが実行されること

3. **ロールバック可能であること**
   - 問題が起きたら戻せること
   - 影響範囲が把握できること

AI仕様駆動開発は、これらすべてを仕組み化します。

#### 責任を取れない状態の具体例

「責任を取れない状態」とは具体的にどういう状況でしょうか。実際にあった例を紹介します。

あるスタートアップで、AIに「課金機能を実装して」と依頼し、生成されたコードをほぼそのままマージしました。レビューは「動いているからOK」という軽いものでした。

1ヶ月後、顧客から「二重課金された」という報告が入りました。調査を始めましたが、以下の問題に直面しました。

まず、**コードが理解できない**。AIが生成した課金ロジックは複雑で、なぜこの順序で処理しているのか、担当者にも説明できませんでした。レビュー時に深く理解していなかったためです。

次に、**テストがない**。正常系の簡単なテストしかなく、ネットワークエラー時のリトライ動作がテストされていませんでした。二重課金の原因は、リトライ処理のバグでした。

最後に、**変更理由が追跡できない**。なぜこのリトライ回数なのか、なぜこのタイムアウト値なのか、どこにも記録がありませんでした。

結局、原因特定に3日、修正と検証に2日、顧客対応に1週間かかりました。責任を取れる状態——レビュー可能、テストあり、ロールバック可能——が整っていれば、問題は発生しなかったか、発生しても数時間で解決できたはずです。

---

## テスト戦略を先に固める意味

### テストは「仕様の検証」

テストを先に考えることの本質的な意味は、**「正しさの定義」を先に決める**ことです。

```
従来：
コード書く → テスト書く → 「これでいいか」を確認

AI仕様駆動：
仕様を書く → テスト戦略を定義 → AIがコード＋テスト生成 → 検証
```

テスト戦略が明確なら、AIに「これをテストしろ」と指示できます。

### テスト戦略の定義項目

TESTING.mdには以下を含めます。

```markdown
## テスト戦略

### テストの種類と比率
- Unit: 70%（ビジネスロジック中心）
- Integration: 20%（API/DB連携）
- E2E: 10%（クリティカルパス）

### 何をテストするか
- ビジネスロジックのすべてのパス
- 境界値（0, 1, max, max+1）
- エラーケース
- セキュリティ関連（認証、認可、入力検証）

### 何をテストしないか
- 外部ライブラリの内部動作
- フレームワークの標準動作
- UIの見た目（E2Eで最低限）

### モック戦略
- 外部API：必ずモック
- DB：Unitはモック、Integrationは実DB
- 時間：固定値を注入
- ランダム：シード固定
```

### AIへの効果

テスト戦略が定義されていると、AIは次のように動作します。

- 「この関数にはユニットテストが必要」と判断できる
- 「境界値テストを追加すべき」と認識できる
- 「モックの使い方」を正しく適用できる

#### テスト戦略がないときのAIの挙動

テスト戦略が定義されていない場合、AIはどのようなテストを生成するでしょうか。実際に観察された傾向を紹介します。

まず、**カバレッジが偏る**傾向があります。正常系のテストは充実しますが、エラーケースや境界値のテストが不足しがちです。AIは「典型的なテスト」を学習しているため、例外的なケースへの意識が低くなります。

次に、**モックの使い方が不適切** になりがちです。「外部APIはモック」「DBは実DBを使用」といった方針がないと、AIは一貫性のないモック戦略でテストを書きます。あるテストではDBをモックし、別のテストでは実DBを使う——といった混乱が生じます。

また、**テストの粒度が安定しない**傾向もあります。1つの関数に対して10個のテストを書くこともあれば、複雑な関数でも1つのテストで済ませることもあります。「ビジネスロジックは手厚く、ユーティリティは最低限」といった基準がないためです。

さらに、**不必要なテストが増える**こともあります。フレームワークの標準動作をテストしたり、ライブラリの内部実装をテストしたりすることがあります。「何をテストしないか」が明示されていないためです。

TESTING.mdでテスト戦略を明示することで、これらの問題を防ぎ、一貫した品質のテストが生成されるようになります。

---

## AIの暴走を止めるガードレール

### ガードレールの3層構造

![ガードレールの3層構造](../images/ch11-guardrail-structure.jpeg)

AIの品質を担保するために、3層のガードレールを設けます。

- **第1層：仕様による制約** — スコープ外の機能を作らない、定義されたパターンに従う
- **第2層：自動チェックによる検出** — 静的解析（ESLint, TypeScript）、セキュリティスキャン、テスト実行
- **第3層：人間によるレビュー** — コードレビュー、セキュリティレビュー、アーキテクチャレビュー

各層の詳細を見ていきましょう。

### 第1層：仕様による制約

AIに「やってはいけないこと」を明示します。

```markdown
## セキュリティ制約（ARCHITECTURE.mdより）

### 禁止事項
- ユーザー入力を直接SQLに埋め込まない
- 認証なしでAPIを公開しない
- 秘密情報をログに出力しない
- 動的コード実行や危険なDOM操作を行わない

### 必須事項
- すべての入力をバリデーションする
- すべてのAPIに認証ミドルウェアを適用する
- 機密データは暗号化して保存する
```

### 第2層：自動チェック

CIパイプラインで自動検出します。

```yaml
# .github/workflows/security.yml
name: Security Check

on: [push, pull_request]

jobs:
  security:
    runs-on: ubuntu-latest
    steps:
      # 依存関係の脆弱性チェック
      - name: Dependency scan
        run: npm audit --audit-level=high

      # コードのセキュリティスキャン
      - name: CodeQL Analysis
        uses: github/codeql-action/analyze@v2

      # 機密情報の漏洩チェック
      - name: Secret scan
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
```

### 第3層：人間によるレビュー

最終的には人間が確認します。

```markdown
## セキュリティレビューチェックリスト

### 認証・認可
- [ ] すべてのエンドポイントに認証が設定されているか
- [ ] 権限チェックが適切に行われているか
- [ ] セッション管理は安全か

### 入力検証
- [ ] すべてのユーザー入力がバリデーションされているか
- [ ] SQLインジェクション対策がされているか
- [ ] XSS対策がされているか

### データ保護
- [ ] 機密データは暗号化されているか
- [ ] ログに機密情報が出力されていないか
- [ ] エラーメッセージに機密情報が含まれていないか
```

---

## 監査可能性：いつ誰が何を変えたかを追える

### なぜ監査可能性が重要か

問題が起きたとき、「なぜこうなったか」を追跡できる必要があります。

- セキュリティインシデント時の調査
- コンプライアンス監査への対応
- バグの原因特定

### 追跡可能性の確保

#### 1. コミット履歴

すべての変更はGitで追跡されます。

```bash
# いつ、誰が、何を変えたか
git log --oneline --author="name" --since="2026-01-01"

# 特定のファイルの変更履歴
git log --follow -p -- path/to/file
```

#### 2. PRとIssueの紐付け

すべてのPRはIssueに紐付けます。

```markdown
## PR #42: ログイン機能の実装

Closes #42

### 変更内容
- ログインAPI追加
- セッション管理追加
```

これにより、「なぜこの変更が必要だったか」がIssueから追跡できます。

#### 3. ADR（Architecture Decision Record）

重要な決定は文書化します。

```markdown
# ADR-006: パスワードハッシュアルゴリズムの選定

## 日付
2024-01-15

## 決定者
@security-team, @tech-lead

## 決定
Argon2idを使用する

## 理由
- OWASP推奨
- bcryptより高いセキュリティ
- ライブラリが安定している

## 代替案
- bcrypt: 却下（Argon2idの方がセキュア）
- scrypt: 却下（ライブラリが不安定）
```

#### 4. 監査ログ

重要な操作は監査ログに記録します。

```typescript
// 監査ログの記録
await auditService.log({
  action: 'USER_LOGIN',
  actor: userId,
  target: { type: 'user', id: userId },
  details: { ip: request.ip, userAgent: request.headers['user-agent'] },
  timestamp: new Date(),
});
```

---

## AIが書いたコードと人間が書いたコード

### 区別する必要があるか？

**必要ありません。**

レビューを通過し、テストをパスし、承認されたコードは、誰が書いたかに関係なく「チームのコード」です。

### 重要なのはプロセス

AIが書いたか人間が書いたかより、**適切なプロセスを経たか** が重要です。

- [ ] 仕様に基づいているか
- [ ] レビューを受けたか
- [ ] テストをパスしたか
- [ ] セキュリティチェックをパスしたか
- [ ] 承認されたか

これらすべてをクリアしたコードは、品質が担保されています。

---

## 章末チェックリスト

- [ ] テスト戦略（TESTING.md）を整備する
- [ ] セキュリティ制約をARCHITECTURE.mdに明記する
- [ ] CIにセキュリティスキャンを追加する
- [ ] セキュリティレビューチェックリストを作成する
- [ ] PRテンプレートにIssue紐付けを必須にする

---

## 🥷 AI侍道場 - 品質は文化である

【AI侍】「この章で学んだ『品質』——それは**プロセスが作る**ものである」

【DJ町娘】「AI侍さん、AIが書いたコードって、品質大丈夫なんですか？」

【AI侍】「**品質は『誰が書いたか』では決まらぬ。『どうチェックしたか』で決まる**」

【DJ町娘】「どうチェックしたか...？」

【AI侍】「うむ。人間が書いたコードでも、レビューもテストもなければ品質は低い。AIが書いたコードでも、**仕様に基づき、レビューされ、テストされれば**品質は高い」

【DJ町娘】「確かに！プロセスが大事なんですね」

【AI侍】「そうだ。品質は『ツール』や『技術』ではなく、**『文化』**が作る。仕様を書く文化、レビューする文化、テストする文化——これらが揃えば、誰が書いても品質は担保される」

---

### 🗡️ AI侍の秘伝書

AI時代の品質を担保する3つの極意を授ける。

#### 秘伝その1：4層のチェックで品質を作れ

品質は1つのチェックでは作れぬ。**4層のチェック**を重ねよ。

**Layer 1：仕様チェック**
- Issueに受け入れ基準があるか
- 技術的制約が明記されているか
- スコープが明確か

**Layer 2：実装チェック（自動）**
- Linterが通っているか
- 型チェックが通っているか
- セキュリティスキャンが通っているか

**Layer 3：レビューチェック（人間）**
- 仕様通りに実装されているか
- ビジネスルールを満たしているか
- セキュリティリスクはないか

**Layer 4：テストチェック**
- 受け入れ基準をすべて満たしているか
- エッジケースをカバーしているか
- 性能要件を満たしているか

この4層を通過したコードは、高品質である。

#### 秘伝その2：セキュリティは「制約」として明示せよ

「セキュリティに気をつけて」——これでは曖昧すぎる。**具体的な制約**として明示せよ。

```markdown
## セキュリティ制約（ARCHITECTURE.md）
- パスワードは必ずArgon2idでハッシュ化
- ユーザー入力は必ずエスケープ
- 認証トークンはhttpOnlyクッキーに保存
- SQLは必ずプリペアドステートメント使用
- 外部API呼び出しはタイムアウト設定必須
```

制約として書けば、AIもレビュアーも**チェックリストとして使える**。

#### 秘伝その3：責任は「承認者」が取れ

「AIが書いたから責任取れない」——これは逃げである。**承認した者が責任を取る**。

- AIが書いたコード → レビュアーが承認 → レビュアーが責任
- 人間が書いたコード → レビュアーが承認 → レビュアーが責任

責任の所在は**「誰が書いたか」ではなく「誰が承認したか」**である。

---
