# 第12章　ツール実装：Claude Code / GitHub Copilotで"仕様駆動"を自動化する

## この章で学ぶこと

- Claude CodeとGitHub Copilotの両方で仕様駆動開発を自動化する方法
- 使用するツールに関わらず、同等のレビュー機能を実現できること
- 各ツール固有のエージェント/スキルの設計方法

---

## 読者へのメッセージ

本章では、**Claude Code**と**GitHub Copilot**の両方を取り上げます。

どちらのツールでも、仕様駆動開発を支援する**同等のエージェント機能**を利用できます。普段お使いのツールに合わせて、該当するセクションを参照してください。

**重要な違い**:

| 観点 | Claude Code | GitHub Copilot |
|------|-------------|----------------|
| プラグイン | pr-review-toolkitなど公式提供済み | なし（自作が必要） |
| 準備の手間 | すぐに使える | 本章のテンプレートを導入 |
| カスタマイズ | Skills/Agentsファイル | `.github/agents/*.agent.md` |

本章では、GitHub Copilotユーザー向けに**6つのエージェントテンプレート**を提供します。これらはClaude Codeのpr-review-toolkitと同等の機能を実現するためのものです。

---

## Skillsの考え方

### Skillsとは

Claude CodeのSkillsは、**特定のワークフローをモジュール化**したものです。

繰り返し行う作業を「スキル」として定義しておくことで：

- 毎回同じ指示を書かなくて済む
- チーム全体で統一された方法で作業できる
- プロジェクト横断で再利用できる

### スキルの基本構造

```markdown
# スキル名

## 説明
このスキルが何をするか

## トリガー
どんなときにこのスキルを使うか

## 実行手順
1. ステップ1
2. ステップ2
3. ステップ3

## 入力
- 必要な情報1
- 必要な情報2

## 出力
- 生成されるもの
```

### スキルを作るべきタイミング

「どの作業をスキル化すべきか」という判断は難しいものです。以下の基準を参考にしてください。

**スキル化すべき作業の条件**:

1. **繰り返し発生する**：週に3回以上同じ作業をしている
2. **手順が定型化できる**：毎回ほぼ同じステップを踏む
3. **ミスが起きやすい**：手順を忘れたり、漏れが発生したりする

逆に、スキル化しないほうがよいケースもあります。

**スキル化を避けるべきケース**:

- 頻度が低い作業（月に1回程度）：スキルを作るコストに見合わない
- 毎回判断が異なる作業：定型化が難しく、スキルの柔軟性が足りなくなる
- 一度きりの作業：使い回せないスキルは無駄

まずは「この作業、もう3回目だな」と感じたらスキル化を検討しましょう。最初から完璧なスキルを作る必要はありません。簡単なスキルから始めて、使いながら改善していく方が効率的です。

---

## 仕様駆動を支援するスキル例

### スキル1：プロジェクト初期化

```markdown
# spec-init

## 説明
7文書構成を新規プロジェクトに導入する

## トリガー
「7文書を初期化して」「spec-initを実行して」

## 実行手順
1. docs/ディレクトリを作成
2. 7つのテンプレートファイルを生成
3. MASTER.mdにプロジェクト情報を記入
4. .claude/settings.jsonにドキュメントパスを設定

## 入力
- プロジェクト名
- 技術スタック（言語、フレームワーク、DB）
- 簡単な説明

## 出力
- docs/MASTER.md
- docs/PROJECT.md
- docs/ARCHITECTURE.md
- docs/DOMAIN.md
- docs/PATTERNS.md
- docs/TESTING.md
- docs/DEPLOYMENT.md
```

### スキル2：Issue作成支援

```markdown
# create-issue

## 説明
仕様駆動に適したIssueを作成する

## トリガー
「Issueを作って」「タスクをIssue化して」

## 実行手順
1. ユーザーから機能の概要をヒアリング
2. 関連する仕様文書（DOMAIN.md, ARCHITECTURE.md）を参照
3. 受け入れ基準を具体化
4. 技術的制約を洗い出し
5. スコープ外を明確化
6. Issue形式で出力

## 入力
- 機能の概要
- 関連する既存機能（あれば）

## 出力
- Issue本文（Markdown形式）
- 関連文書へのリンク
```

### スキル3：文書検証

```markdown
# validate-docs

## 説明
7文書の整合性と完全性を検証する

## トリガー
「ドキュメントを検証して」「validate-docs」

## 実行手順
1. 全文書のFrontmatterを検証
2. 内部リンクの有効性を確認
3. 用語の統一性をチェック
4. 文書間の参照整合性を確認
5. MASTER.mdの索引が最新か確認
6. 問題点をレポート

## 入力
- 検証対象のディレクトリ（デフォルト: docs/）

## 出力
- 検証結果レポート
- 修正が必要な箇所のリスト
```

### スキル4：影響度評価

```markdown
# assess-impact

## 説明
文書変更の影響度を評価する

## トリガー
「この変更の影響度は？」「assess-impact」

## 実行手順
1. 変更内容を分析
2. 影響を受ける文書を特定
3. 影響を受けるコードを特定
4. 影響度（LOW/MEDIUM/HIGH）を判定
5. 対応チェックリストを生成

## 入力
- 変更内容の説明
- または変更対象の文書パス

## 出力
- 影響度（LOW/MEDIUM/HIGH）
- 影響を受ける文書リスト
- 対応チェックリスト
- HIGH の場合はADRテンプレート
```

### スキル5：コミット前チェック

```markdown
# pre-commit-check

## 説明
コミット前に仕様準拠を確認する

## トリガー
コミット時に自動実行（huskyフック）

## 実行手順
1. 変更されたファイルを取得
2. 関連する仕様文書を特定
3. 仕様との整合性を確認
4. PATTERNS.mdのルールに違反していないか確認
5. MASTER.mdの更新が必要か判断
6. 問題があれば警告

## 入力
- ステージングされたファイル

## 出力
- チェック結果（OK/警告/エラー）
- 警告・エラーの詳細
```

### スキル同士を組み合わせる

個々のスキルは単独でも便利ですが、組み合わせることでより強力なワークフローを構築できます。

#### 典型的なワークフロー例

プロジェクト開始から日々の開発まで、スキルを連携させた流れを示します。

```text
プロジェクト開始時:
  spec-init → validate-docs → create-issue
  （初期化 → 検証 → 最初のIssue作成）

機能開発時:
  create-issue → [AIで実装] → pre-commit-check → assess-impact
  （Issue作成 → 実装 → コミット前チェック → 影響度評価）

リリース前:
  validate-docs → multi-review → assess-impact
  （文書検証 → 多視点レビュー → 影響度の最終確認）
```

#### スキル連携のポイント

スキルを連携させるときは、前のスキルの出力が次のスキルの入力になるように設計します。

例えば、`create-issue`が出力する「関連文書へのリンク」は、AIが実装するときのコンテキストになります。また、`assess-impact`が出力する「影響を受ける文書リスト」は、`validate-docs`でチェックすべき対象になります。

このように、スキル間でデータが自然に流れる設計にすると、手動での情報の受け渡しが減り、ワークフロー全体が効率化します。

---

## サブエージェントによる多視点レビュー

### なぜ多視点が必要か

1人のレビュワー（人間でもAIでも）には盲点があります。

**多視点レビュー** は、異なる観点を持つ複数のエージェントが同時にレビューすることで、盲点をカバーします。

### レビュワーエージェントの例

#### セキュリティレビュワー

```markdown
# security-reviewer

## 役割
セキュリティ観点でコードをレビューする

## 確認観点
- 認証・認可の実装
- 入力検証の網羅性
- 機密データの取り扱い
- 依存ライブラリの脆弱性
- ログ出力に機密情報が含まれていないか

## 出力形式
## セキュリティレビュー結果

### 重大な問題
- [ファイル:行] 問題の説明

### 警告
- [ファイル:行] 懸念点の説明

### 推奨事項
- 改善提案
```

#### パフォーマンスレビュワー

```markdown
# performance-reviewer

## 役割
パフォーマンス観点でコードをレビューする

## 確認観点
- N+1クエリの有無
- 不要なループ処理
- メモリ効率
- キャッシュ戦略
- 非同期処理の適切性

## 出力形式
## パフォーマンスレビュー結果

### 問題
- [ファイル:行] 問題の説明と推定影響

### 最適化提案
- 改善案と期待される効果
```

#### アーキテクチャレビュワー

```markdown
# architecture-reviewer

## 役割
既存アーキテクチャとの整合性をレビューする

## 確認観点
- レイヤー構成の遵守
- 依存関係の方向
- 責務の分離
- ARCHITECTURE.mdとの整合性
- PATTERNS.mdのパターン適用

## 出力形式
## アーキテクチャレビュー結果

### 違反
- [ファイル] 違反内容と参照すべき文書

### 改善提案
- よりよい設計案
```

### 複数エージェントの統合実行

```markdown
# multi-review

## 説明
複数のレビュワーエージェントを並行実行する

## トリガー
「PRをレビューして」「multi-review」

## 実行手順
1. 変更ファイルを取得
2. 以下のエージェントを並行実行
   - security-reviewer
   - performance-reviewer
   - architecture-reviewer
3. 結果を統合してレポート

## 出力
## 統合レビュー結果

### セキュリティ
[security-reviewerの結果]

### パフォーマンス
[performance-reviewerの結果]

### アーキテクチャ
[architecture-reviewerの結果]

### 総合判定
[Approve / Request Changes / Comment]
```

### pr-review-toolkit（公式プラグイン）

Claude Codeには、PRレビュー専用の公式プラグイン「**pr-review-toolkit**」が提供されています。6つの専門エージェントを組み合わせた包括的なレビューシステムです。

#### 使い方

```bash
# すべてのレビューを実行
/pr-review-toolkit:review-pr

# 特定のアスペクトのみ
/pr-review-toolkit:review-pr tests errors

# すべてを並列実行
/pr-review-toolkit:review-pr all parallel
```

#### 6つの専門エージェント

| エージェント | 役割 | 主な検出対象 |
|-------------|------|-------------|
| code-reviewer | コード品質 | CLAUDE.md違反、バグ、スタイル問題 |
| silent-failure-hunter | エラーハンドリング | 空のcatchブロック、沈黙する失敗 |
| code-simplifier | 簡潔化 | ネスト過多、冗長コード |
| comment-analyzer | コメント品質 | 不正確なコメント、コメント腐れ |
| pr-test-analyzer | テスト分析 | テスト不足、エッジケース漏れ |
| type-design-analyzer | 型設計 | カプセル化不足、不変性の問題 |

#### code-reviewerの信頼度スコア

code-reviewerは検出した問題に0-100の信頼度スコアを付与し、**80以上のみを報告**します。

| スコア | 意味 | 報告 |
|--------|------|------|
| 0-25 | 誤検出または既存の問題 | しない |
| 26-50 | マイナー（ガイドラインに明記なし） | しない |
| 51-79 | 有効だが低影響 | しない |
| 80-90 | 重要な問題 | する |
| 91-100 | クリティカル | 必ずする |

この仕組みにより、ノイズの少ない高品質なレビュー結果が得られます。

---

## GitHub Copilot Agents

> **Note**: GitHub Copilotには、Claude Codeのpr-review-toolkitのような**公式プラグインが提供されていません**。同等の機能を実現するには、本セクションで紹介するエージェントテンプレートを自分でリポジトリに追加する必要があります。

### GitHub Copilot Agentsとは

GitHub Copilotのカスタムエージェントは、**特定のタスクに特化したAIの専門家**を定義できる機能です。VS Code 1.107以降で利用可能です。

| 項目 | 内容 |
|------|------|
| 保存場所 | `.github/agents/` フォルダ |
| ファイル形式 | `*.agent.md`（Markdown） |
| 対応環境 | VS Code 1.107+、GitHub.com |

### 4種類のエージェントタイプ

GitHub Copilotには4種類のエージェントがあります。

| 種類 | 実行場所 | 特徴 | 用途 |
|------|---------|------|------|
| ローカル | VS Code | 対話的・リアルタイム | 小〜中規模タスク |
| バックグラウンド | VS Code | Git worktreeで並行作業 | 大規模リファクタ |
| クラウド | GitHub.com | 自律的にPR作成 | Issue解決 |
| サブ | 親エージェント内 | 専門タスクを委譲 | 専門知識が必要な部分 |

### カスタムエージェントの作成方法

`.github/agents/` ディレクトリに `*.agent.md` ファイルを作成します。

```markdown
---
description: エージェントの目的や役割の説明
tools:
  - "*"
---

# エージェント名

## 役割
エージェントの役割を説明

## 確認観点
- チェックポイント1
- チェックポイント2

## 出力形式
期待する出力フォーマット
```

### VS Code設定

カスタムエージェントを有効にするには、VS Codeの `settings.json` に以下を追加します。

```json
{
  "github.copilot.chat.cli.customAgents.enabled": true
}
```

### 仕様駆動開発向けエージェント（6種）

以下は、Claude Codeのpr-review-toolkitと同等の機能を実現するためのエージェントテンプレートです。

#### 1. code-reviewer.agent.md

```markdown
---
description: プロジェクトガイドラインへの準拠をチェックし、バグ、スタイル違反、コード品質問題を検出するコードレビューエージェント
tools:
  - "*"
---

# Code Reviewer

プロジェクトガイドラインへの準拠をチェックし、高信頼度の問題のみを報告するコードレビューエージェントです。

## 役割

- CLAUDE.md、README.md、その他のプロジェクトガイドラインとの照合
- バグ検出
- スタイル違反の特定
- コード品質問題の発見

## 分析プロセス

1. プロジェクトのガイドラインファイル（CLAUDE.md等）を読み込む
2. 変更されたファイルを特定する（git diff）
3. 各変更をガイドラインと照合する
4. 問題に信頼度スコアを付与する

## 信頼度スコア

各問題には0-100の信頼度スコアを付与してください：

| スコア | 意味 | 報告 |
|--------|------|------|
| 0-25 | 誤検出または既存の問題 | 報告しない |
| 26-50 | マイナーな指摘（ガイドラインに明記なし） | 報告しない |
| 51-75 | 有効だが低影響 | 報告しない |
| 76-90 | 重要な問題 | 報告する |
| 91-100 | クリティカルなバグまたは明示的な違反 | 必ず報告 |

**報告閾値: 信頼度80以上のみ報告**

## 出力形式

## Code Review Results

### Critical Issues (信頼度 91-100)
- [ファイル名:行番号] 問題の説明
  - 信頼度: XX
  - 理由: なぜこれが問題か
  - 修正提案: どう修正すべきか

### Important Issues (信頼度 76-90)
- [ファイル名:行番号] 問題の説明
  - 信頼度: XX
  - 理由: なぜこれが問題か
  - 修正提案: どう修正すべきか

### Summary
- 検出された問題数: X
- Critical: X
- Important: X

## 注意事項

- 信頼度80未満の問題は報告しない
- 既存のコード（変更されていない部分）の問題は報告しない
- 推測や曖昧な指摘は避ける
- 具体的な修正提案を含める
```

#### 2. error-handler-hunter.agent.md

```markdown
---
description: エラーハンドリングの品質を検査し、沈黙する失敗を検出するエージェント
tools:
  - "*"
---

# Error Handler Hunter

沈黙する失敗を許さない、エラーハンドリングの厳格な検査官です。

## 役割

- try-catchブロックの検査
- 沈黙する失敗の検出
- 空のcatchブロックの禁止
- フォールバックロジックの正当性確認

## コア原則（譲歩不可）

1. 沈黙する失敗は受け入れられない
2. ユーザーは実行可能なフィードバックに値する
3. フォールバックは明示的で正当化される必要がある
4. キャッチブロックは特定的でなければならない

## 重大度レベル

| レベル | 説明 | 例 |
|--------|------|-----|
| CRITICAL | サイレント失敗、ブロードcatch | 空のcatchブロック |
| HIGH | 不十分なエラーメッセージ | console.log("error") のみ |
| MEDIUM | コンテキスト不足 | エラーの原因が不明確 |

## 出力形式

## Error Handling Analysis Results

### CRITICAL Issues
- [ファイル名:行番号] 問題の説明
  - コード: 問題のあるコード
  - 問題: 何が問題か
  - 修正提案: 推奨される修正

### Summary
- CRITICAL: X
- HIGH: X
- MEDIUM: X
```

#### 3. test-analyzer.agent.md

```markdown
---
description: テストカバレッジの品質を分析し、クリティカルなギャップを特定するエージェント
tools:
  - "*"
---

# Test Analyzer

行カバレッジではなく、動作カバレッジの観点からテスト品質を分析するエージェントです。

## 役割

- 動作カバレッジの分析
- クリティカルなテストギャップの特定
- エッジケースとエラー条件のカバレッジ確認

## 識別対象のギャップ

1. テストされていないエラーハンドリングパス
2. 境界条件のエッジケース（空入力、null、最大値/最小値）
3. クリティカルなビジネスロジック分岐
4. ネガティブテストケース
5. 非同期/並行処理

## 優先度スケール

| 優先度 | 意味 |
|--------|------|
| 9-10 | クリティカル（データ損失、セキュリティ、システム障害の可能性） |
| 7-8 | 重要（ユーザー向けエラーの可能性） |
| 5-6 | エッジケース（混乱や軽微な問題） |
| 3-4 | Nice-to-have |
| 1-2 | オプショナル |

## 出力形式

## Test Coverage Analysis Results

### Critical Gaps (優先度 9-10)
- [機能名] ファイル: path/to/file.ts
  - テストされていない動作: 説明
  - リスク: 影響
  - 優先度: X
  - 推奨テストケース: 具体的なテスト案
```

#### 4. code-simplifier.agent.md

```markdown
---
description: コードの簡潔性と可読性を向上させるエージェント。機能を変更せずに、不要な複雑性を排除します
tools:
  - "*"
---

# Code Simplifier

機能を保持したまま、コードの簡潔性と可読性を向上させるエージェントです。

## 役割

- 不要な複雑性の排除
- 可読性の向上
- 冗長なコードの削減

## 簡潔化のルール

### 推奨する変更

1. ネストした三項演算子 → if/else文へ
2. 深いネスト → 早期リターンパターンへ
3. 巧妙なコード → 分かりやすいコードへ

### 禁止事項

- 機能の変更
- 新機能の追加
- テストの削除

## 出力形式

## Code Simplification Results

### Simplification Opportunities
- [ファイル名:行番号]
  - 現在のコード: ...
  - 提案: ...
  - 理由: なぜこの変更が可読性を向上させるか

## 注意事項

- 機能を絶対に変更しない
- 最近変更されたコードのみに焦点を当てる
- 簡潔性より明確性を優先する
```

#### 5. comment-analyzer.agent.md

```markdown
---
description: コードコメントの正確性、完全性、長期的な保守性を分析するエージェント
tools:
  - "*"
---

# Comment Analyzer

コードコメントの品質を分析し、技術的負債を防ぐエージェントです。

## 役割

- コメントと実コードの照合
- コメント腐れ（技術的負債）の検出
- 誤解を招く・時代遅れなコメントの特定

## 検証プロセス

1. 事実精度の確認（関数署名、説明された動作）
2. 完全性の評価（仮定、副作用、エラー状態）
3. 長期的価値の評価（「なぜ」を説明しているか）
4. 誤解要素の特定（曖昧性、古い参照）

## 出力形式

## Comment Analysis Results

### Critical Issues（事実として不正確）
- [ファイル名:行番号]
  - コメント: "..."
  - 問題: コメントが実際のコードと矛盾
  - 推奨修正: ...

### Improvement Opportunities（改善可能）
- [ファイル名:行番号]
  - 問題: 情報が不完全
  - 推奨追加内容: ...
```

#### 6. type-design-analyzer.agent.md

```markdown
---
description: 型設計の品質と不変性を分析するエージェント
tools:
  - "*"
---

# Type Design Analyzer

型設計品質と不変性の表現を分析し、堅牢な型システムの構築を支援するエージェントです。

## 役割

- 型カプセル化の評価
- 不変性表現の分析
- アンチパターンの検出

## 評価軸（各1-10スコア）

| 軸 | 評価内容 |
|----|----------|
| Encapsulation | 内部実装の隠蔽度 |
| Invariant Expression | 不変性の型による表現度 |
| Invariant Usefulness | 実バグ防止への有効性 |
| Invariant Enforcement | 構築時・変異時の検証度 |

## アンチパターン

- 貧血ドメインモデル（データのみで振る舞いがない）
- 変更可能な内部の公開
- ドキュメント依存の不変性
- 構築境界での検証不足

## 出力形式

## Type Design Analysis Results

### [型名]
- ファイル: path/to/file.ts
- スコア: Encapsulation X/10, Invariant Expression X/10, ...
- 総合スコア: X/10
- 検出されたアンチパターン: ...
- 改善提案: ...
```

### エージェントの呼び出し方

VS CodeのCopilot Chatで `@` に続けてエージェント名を入力します。

```text
@code-reviewer このPRをレビューして
@test-analyzer テストカバレッジを分析して
@error-handler-hunter エラーハンドリングを検査して
```

### 推奨ワークフロー

**コミット前**:

```text
@code-reviewer
@error-handler-hunter
```

**PR作成前**:

```text
@code-reviewer
@test-analyzer
@error-handler-hunter
@comment-analyzer
```

**新しい型を追加した場合**:

```text
@type-design-analyzer
```

### Premium Requestsとコスト

GitHub Copilotのカスタムエージェントは**Premium Requests**を消費します。

| モデル | 消費量 |
|--------|--------|
| GPT-4o / GPT-4.1 | 無料 |
| Claude Haiku 4.5 | 0.33倍 |
| Claude Sonnet 4 / 4.5 | 1倍 |
| Claude Opus 4.5 | 3倍 |

コストを抑えたい場合は、GPT-4oを使用することで無料でエージェントを実行できます。

> **注**: Premium Requestsの詳細な料金体系は[GitHub Docs](https://docs.github.com/en/copilot/concepts/billing/copilot-requests)を参照してください。

---

## Claude Code vs GitHub Copilot 比較

### 基本比較

| 観点 | Claude Code Skills | GitHub Copilot Agents |
|------|-------------------|----------------------|
| 実行環境 | Claude Code CLI | VS Code / GitHub.com |
| 設定ファイル | plugin.json + commands/ | .github/agents/*.agent.md |
| Git連携 | Bash経由 | ネイティブ（worktree, PR作成） |
| 並列実行 | 順次 | Background/Sub-Agents |
| コスト | サブスクリプション | Premium Requests |
| 公式プラグイン | pr-review-toolkit等あり | なし（自作が必要） |

### レビューエージェント対応表

| 目的 | Claude Code (pr-review-toolkit) | GitHub Copilot Agent |
|------|--------------------------------|---------------------|
| コードレビュー | code-reviewer | code-reviewer.agent.md |
| サイレント失敗検出 | silent-failure-hunter | error-handler-hunter.agent.md |
| コード簡素化 | code-simplifier | code-simplifier.agent.md |
| コメント分析 | comment-analyzer | comment-analyzer.agent.md |
| テスト分析 | pr-test-analyzer | test-analyzer.agent.md |
| 型設計評価 | type-design-analyzer | type-design-analyzer.agent.md |
| 包括的レビュー | /review-pr | （複数エージェント組み合わせ） |

**どちらのツールを使っても、同等のレビュー機能を実現できます。**

---

## スキルの設計ポイント

### 1. 起動条件（description）の重要性

スキルは「いつ起動するか」が重要です。

```markdown
## 良いdescription
「7文書を初期化したいとき」「新規プロジェクトでspec-initを実行」

## 悪いdescription
「プロジェクト設定」（曖昧すぎる）
```

明確な起動条件により、ユーザーが意図したタイミングでスキルが発動します。

### 2. 入力の明確化

スキルに必要な入力を明確にします。

```markdown
## 入力
- プロジェクト名（必須）：リポジトリ名と同じ
- 技術スタック（必須）：言語、フレームワーク、DBを列挙
- 説明（任意）：1〜2文で概要
```

### 3. 冪等性

スキルは何度実行しても同じ結果になるように設計します。

```markdown
## 冪等性の確保
- ファイルが存在する場合は上書きしない（または確認する）
- 部分的に実行された場合も再実行で完了する
```

### 4. エラーハンドリング

失敗時の動作を定義します。

```markdown
## エラー時の動作
- 途中で失敗した場合、完了したステップを報告
- ロールバックが必要な場合は手順を提示
- 再実行方法を案内
```

### うまくいかなかったスキルの事例

スキル設計で実際に起きた失敗例を紹介します。同じ轍を踏まないための参考にしてください。

#### descriptionが曖昧で誤発動

あるチームが「code-review」というスキルを作りました。descriptionを「コードをレビューする」と書いたところ、「このコードをレビューして」以外にも、「このコードの意味を教えて」「このコードのバグを探して」など、意図しないタイミングで発動するようになりました。

解決策として、descriptionを「PRのコード変更をPATTERNS.mdに基づいてレビューする」と具体化しました。「PRの」「PATTERNS.mdに基づいて」という限定条件を入れることで、意図したタイミングでのみ発動するようになりました。

#### 入力が複雑すぎて使われない

別のチームが「full-spec-check」というスキルを作りました。入力として「対象ディレクトリ」「チェックレベル（厳密/標準/緩め）」「除外パターン」「レポート形式」「通知先」の5つを要求していました。

結果、誰も使いませんでした。毎回5つの入力を指定するのが面倒で、「手動でチェックした方が早い」となったのです。

解決策として、入力を「対象ディレクトリ」だけにし、他はデフォルト値を持つオプションにしました。「90%のケースはデフォルトで十分」という設計に変えたところ、利用率が上がりました。

#### 粒度が大きすぎて柔軟性がない

「deploy-all」というスキルは、テスト実行→ビルド→デプロイ→通知をすべて一気に実行するものでした。しかし、「テストだけ実行したい」「ビルドまでで止めたい」というケースに対応できず、結局使われなくなりました。

解決策として、「run-tests」「build」「deploy」「notify」に分割し、必要な組み合わせで使えるようにしました。さらに、よく使う組み合わせを「deploy-standard」としてまとめることで、利便性と柔軟性を両立しました。

---

## 章末チェックリスト

### 共通

- [ ] プロジェクトで繰り返している作業を洗い出す
- [ ] 最もよく使う作業をスキル/エージェント化する
- [ ] description（起動条件）を明確に書く
- [ ] 複数視点レビューの導入を検討する
- [ ] スキル/エージェントをチームで共有する方法を決める

### Claude Code ユーザー

- [ ] pr-review-toolkitプラグインを導入する
- [ ] `/pr-review-toolkit:review-pr` をPR前に実行する習慣をつける
- [ ] 必要に応じてカスタムスキルを作成する

### GitHub Copilot ユーザー

- [ ] `.github/agents/` ディレクトリを作成する
- [ ] 本章の6つのエージェントテンプレートを導入する
- [ ] VS Code設定でカスタムエージェントを有効化する
- [ ] `@code-reviewer` などのエージェントをPR前に実行する習慣をつける

---

## 次章への橋渡し

この章では、Claude CodeとGitHub Copilotの両方で仕様駆動開発を自動化する方法を学びました。どちらのツールでも、同等のレビュー機能を実現できることがわかりました。

次章からは**第5部「組織に展開する」** に入ります。個人の取り組みをチーム・組織の標準にする方法を解説します。
